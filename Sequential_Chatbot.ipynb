{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23DFzKyuiakd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.jit import script, trace\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import codecs\n",
        "from io import open\n",
        "import itertools\n",
        "import math\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYnQ_uIUivxW",
        "outputId": "ff731212-9d4a-462d-bffc-23e5bf43122f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load & Preprocess Data**"
      ],
      "metadata": {
        "id": "00WxJwUyi2Wj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**preprocess the data**"
      ],
      "metadata": {
        "id": "YHsOq5upstAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lines_filepath = os.path.join(\"/content\", \"movie_lines.txt\")\n",
        "conv_filepath = os.path.join(\"/content\", \"movie_conversations.txt\")"
      ],
      "metadata": {
        "id": "vQRQyE-zr-IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize some lines\n",
        "with open(lines_filepath, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "    lines = file.readlines()\n",
        "for line in lines[:8]:\n",
        "    print(line.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eMC4myQ3ivt7",
        "outputId": "63c604db-466b-4355-def1-f10ba2f8faf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
            "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
            "L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
            "L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n",
            "L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n",
            "L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n",
            "L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\n",
            "L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splits each line of the file into a dictionary of fields (LineID, characterID, movieID, character, text)\n",
        "line_fields = [\"lineID\", \"characterID\", \"movieID\", \"character\", \"text\"]\n",
        "lines = {}\n",
        "with open(lines_filepath, 'r', encoding='iso-8859-1') as f:\n",
        "    for line in f:\n",
        "        values = line.split(\" +++$+++ \")\n",
        "        # Extract fields\n",
        "        lineObj = {}\n",
        "        for i, field in enumerate(line_fields):\n",
        "            lineObj[field] = values[i]\n",
        "        lines[lineObj['lineID']] = lineObj"
      ],
      "metadata": {
        "id": "1jj-WpbiqEYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the first 3 lines\n",
        "count = 0\n",
        "for line_id, line_data in lines.items():\n",
        "    if count < 3:\n",
        "        print(f\"{line_id}: {line_data}\")\n",
        "        count += 1\n",
        "    else:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsSiI0KWqITS",
        "outputId": "679232b3-8906-4606-b534-955813943b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1045: {'lineID': 'L1045', 'characterID': 'u0', 'movieID': 'm0', 'character': 'BIANCA', 'text': 'They do not!\\n'}\n",
            "L1044: {'lineID': 'L1044', 'characterID': 'u2', 'movieID': 'm0', 'character': 'CAMERON', 'text': 'They do to!\\n'}\n",
            "L985: {'lineID': 'L985', 'characterID': 'u0', 'movieID': 'm0', 'character': 'BIANCA', 'text': 'I hope so.\\n'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Groups fields of lines from `loadlines` into conversations based on *movie_conversations.txt*\n",
        "conv_fields = [\"character1ID\", \"character2ID\", \"movieID\", \"utteranceIDs\"]\n",
        "conversations = []\n",
        "with open(conv_filepath, 'r', encoding='iso-8859-1') as f:\n",
        "    for line in f:\n",
        "        values = line.split(\" +++$+++ \")\n",
        "        # Extract fields\n",
        "        convObj = {}\n",
        "        for i, field in enumerate(conv_fields):\n",
        "            convObj[field] = values[i]\n",
        "        # Convert string result from split to list, since convObj[\"utteranceIDs\"] == ['L598485', 'L598486', ...]\n",
        "        lineIDs = eval(convObj[\"utteranceIDs\"])\n",
        "        # Reassemble lines\n",
        "        convObj[\"lines\"] = []\n",
        "        for lineId in lineIDs:\n",
        "            convObj[\"lines\"].append(lines[lineId])\n",
        "        conversations.append(convObj)"
      ],
      "metadata": {
        "id": "9pzkOY1ZnfL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the first 3 conversations\n",
        "for conv in conversations[:3]:\n",
        "    print(conv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShGHNCmcuEtM",
        "outputId": "d3bcbc5c-c537-43d5-9a3e-f34e00d53d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'character1ID': 'u0', 'character2ID': 'u2', 'movieID': 'm0', 'utteranceIDs': \"['L194', 'L195', 'L196', 'L197']\\n\", 'lines': [{'lineID': 'L194', 'characterID': 'u0', 'movieID': 'm0', 'character': 'BIANCA', 'text': 'Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\n'}, {'lineID': 'L195', 'characterID': 'u2', 'movieID': 'm0', 'character': 'CAMERON', 'text': \"Well, I thought we'd start with pronunciation, if that's okay with you.\\n\"}, {'lineID': 'L196', 'characterID': 'u0', 'movieID': 'm0', 'character': 'BIANCA', 'text': 'Not the hacking and gagging and spitting part.  Please.\\n'}, {'lineID': 'L197', 'characterID': 'u2', 'movieID': 'm0', 'character': 'CAMERON', 'text': \"Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\n\"}]}\n",
            "{'character1ID': 'u0', 'character2ID': 'u2', 'movieID': 'm0', 'utteranceIDs': \"['L198', 'L199']\\n\", 'lines': [{'lineID': 'L198', 'characterID': 'u0', 'movieID': 'm0', 'character': 'BIANCA', 'text': \"You're asking me out.  That's so cute. What's your name again?\\n\"}, {'lineID': 'L199', 'characterID': 'u2', 'movieID': 'm0', 'character': 'CAMERON', 'text': 'Forget it.\\n'}]}\n",
            "{'character1ID': 'u0', 'character2ID': 'u2', 'movieID': 'm0', 'utteranceIDs': \"['L200', 'L201', 'L202', 'L203']\\n\", 'lines': [{'lineID': 'L200', 'characterID': 'u0', 'movieID': 'm0', 'character': 'BIANCA', 'text': \"No, no, it's my fault -- we didn't have a proper introduction ---\\n\"}, {'lineID': 'L201', 'characterID': 'u2', 'movieID': 'm0', 'character': 'CAMERON', 'text': 'Cameron.\\n'}, {'lineID': 'L202', 'characterID': 'u0', 'movieID': 'm0', 'character': 'BIANCA', 'text': \"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\n\"}, {'lineID': 'L203', 'characterID': 'u2', 'movieID': 'm0', 'character': 'CAMERON', 'text': 'Seems like she could get a date easy enough...\\n'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracts pairs of sentences from conversations\n",
        "qa_pairs = []\n",
        "for conversation in conversations:\n",
        "  # Iterate over all the lines of the conversation\n",
        "  for i in range(len(conversation [\"lines\"]) - 1):\n",
        "    inputLine = conversation [\"lines\"][i][\"text\"].strip()\n",
        "    targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
        "    # Filter wrong samples (if one of the lists is empty)\n",
        "    if inputLine and targetLine:\n",
        "      qa_pairs.append([inputLine, targetLine])"
      ],
      "metadata": {
        "id": "4GfEWxeEvxgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_pairs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O99vtkfvwQ-1",
        "outputId": "def47f99-e748-4274-d03b-9f409f7dd1ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.',\n",
              " \"Well, I thought we'd start with pronunciation, if that's okay with you.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define path to new file\n",
        "datafile = os.path.join(\"/content\", \"formatted_movie_lines.txt\")\n",
        "delimiter = '\\t'\n",
        "# Unescape the delimiter\n",
        "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
        "\n",
        "# Write new CSV file\n",
        "print(\"\\nWriting newly formatted file...\")\n",
        "with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
        "    writer = csv.writer(outputfile, delimiter=delimiter)\n",
        "    for pair in qa_pairs:\n",
        "        writer.writerow(pair)\n",
        "print(\"Done writing to file\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Id5eHeGSxPJs",
        "outputId": "64ea8b81-b4be-4a56-a13e-7694d63a6855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Writing newly formatted file...\n",
            "Done writing to file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize some lines\n",
        "datafile = os.path.join(\"/content\", \"formatted_movie_lines.txt\")\n",
        "with open(datafile, 'rb') as file:\n",
        "    lines = file.readlines()\n",
        "for line in lines[:3]:\n",
        "    print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UyPPo8RxVwh",
        "outputId": "39721957-9e74-4d70-d458-e74ef17e935b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b\"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\tWell, I thought we'd start with pronunciation, if that's okay with you.\\r\\n\"\n",
            "b\"Well, I thought we'd start with pronunciation, if that's okay with you.\\tNot the hacking and gagging and spitting part.  Please.\\r\\n\"\n",
            "b\"Not the hacking and gagging and spitting part.  Please.\\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\r\\n\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocess the words"
      ],
      "metadata": {
        "id": "7wlLp6q6xl2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_token = 0   # Used for padding short sentences\n",
        "SOS_token = 1   # Start-of-sentence token <START>\n",
        "EOS_token = 2   # End-of-sentence token <END>\n",
        "\n",
        "class Vocabulary:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3  # Count SOS, EOS, PAD\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.num_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.num_words] = word\n",
        "            self.num_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "    # Remove words below a certain count threshold\n",
        "    def trim(self, min_count):\n",
        "        keep_words = []\n",
        "        for k, v in self.word2count.items():\n",
        "            if v >= min_count:\n",
        "                keep_words.append(k)\n",
        "\n",
        "        print('keep_words {}/{} = {:.4f}'.format(len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)))\n",
        "        # Reinitialize dictionaries\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3  # Count default tokens\n",
        "\n",
        "        for word in keep_words:\n",
        "            self.addWord(word)"
      ],
      "metadata": {
        "id": "1uOB03vgxoJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "precessing text"
      ],
      "metadata": {
        "id": "InbSrCTizfsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn a Unicode string to plain ASCII\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "# Test the function\n",
        "unicodeToAscii(\"Montréal, Française....\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ic1B0b29zhZ8",
        "outputId": "67e6984f-0705-49f1-ea9c-953651fed3ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Montreal, Francaise....'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercase, trim white spaces, lines... and remove non-letter characters.\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    # Replace any .!? by a whitespace + the character --> '.!' = ' .!'\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    # Remove any character that is not a sequence of lower or upper case letters\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    # Remove a sequence of whitespace characters\n",
        "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
        "    return s\n",
        "\n",
        "# Test the function\n",
        "normalizeString(\"aa123aals's   dd?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qOQBEaIhz7AV",
        "outputId": "bb2e0cd1-9652-4e90-e2a1-8266da46adf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'aa aals s dd ?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datafile = os.path.join(\"/content\", \"formatted_movie_lines.txt\")\n",
        "# Read the file and split into lines\n",
        "print(\"Reading and processing file.... Please Wait\")\n",
        "lines = open(datafile, 'r', encoding='utf-8').read().strip().split('\\n')\n",
        "# Split every line into pairs and normalize\n",
        "pairs = [[normalizeString(s) for s in pair.split('\\t')] for pair in lines]\n",
        "print(\"Done Reading!\")\n",
        "voc = Vocabulary(\"/content\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqS0h_mw0kQg",
        "outputId": "03724a2b-c998-4427-9444-44e55aee5cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading and processing file.... Please Wait\n",
            "Done Reading!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKtKVrZr1vMJ",
        "outputId": "737e55e8-54d0-460e-edea-de78e20212d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221282"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pairs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ppti6z0S10DJ",
        "outputId": "18aafd61-344e-4a18-8579-d9ccd6f95e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['can we make this quick ? roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad . again .',\n",
              " 'well i thought we d start with pronunciation if that s okay with you .']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "filtering the text"
      ],
      "metadata": {
        "id": "ymEdTa2o2EXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns True if both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
        "MAX_LENGTH = 10  # Maximum sentence length to consider (max words)\n",
        "def filterPair(p):\n",
        "    # Input sequences need to preserve the last word for EOS token\n",
        "    return len(p[0].split()) < MAX_LENGTH and len(p[1].split()) < MAX_LENGTH\n",
        "\n",
        "# Filter pairs using filterPair condition\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "metadata": {
        "id": "uiLeXJvn0kIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = [pair for pair in pairs if len(pair) > 1]\n",
        "print(\"There are {} pairs/conversations in the dataset\".format(len(pairs)))\n",
        "pairs = filterPairs(pairs)\n",
        "print(\"After filtering, there are {} pairs/conversations\".format(len(pairs)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk7D1wPp1MZj",
        "outputId": "46c6883a-4f5d-4928-80a6-956936b8276f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 221282 pairs/conversations in the dataset\n",
            "After filtering, there are 64271 pairs/conversations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting Rid of Rare Words"
      ],
      "metadata": {
        "id": "qgdrxipj2_y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loop through each pair of and add the question and reply sentence to the vocabulary\n",
        "for pair in pairs:\n",
        "    voc.addSentence (pair[0])\n",
        "    voc.addSentence (pair[1])\n",
        "print(\"Counted words:\", voc.num_words)\n",
        "for pair in pairs[:10]:\n",
        "    print (pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BL6jX93S2-5M",
        "outputId": "e572645b-4892-4e9b-84e0-4e22a0e3085a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counted words: 18008\n",
            "['there .', 'where ?']\n",
            "['you have my word . as a gentleman', 'you re sweet .']\n",
            "['hi .', 'looks like things worked out tonight huh ?']\n",
            "['you know chastity ?', 'i believe we share an art instructor']\n",
            "['have fun tonight ?', 'tons']\n",
            "['well no . . .', 'then that s all you had to say .']\n",
            "['then that s all you had to say .', 'but']\n",
            "['but', 'you always been this selfish ?']\n",
            "['do you listen to this crap ?', 'what crap ?']\n",
            "['what good stuff ?', 'the real you .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MIN_COUNT = 3  # Minimum word count threshold for trimming\n",
        "\n",
        "def trimRareWords(voc, pairs, MIN_COUNT):\n",
        "    # Trim words used under the MIN_COUNT from the voc\n",
        "    voc.trim(MIN_COUNT)\n",
        "\n",
        "    # Filter out pairs with trimmed words\n",
        "    keep_pairs = []\n",
        "    for pair in pairs:\n",
        "        input_sentence = pair[0]\n",
        "        output_sentence = pair[1]\n",
        "        keep_input = True\n",
        "        keep_output = True\n",
        "\n",
        "        # Check input sentence\n",
        "        for word in input_sentence.split(' '):\n",
        "            if word not in voc.word2index:\n",
        "                keep_input = False\n",
        "                break\n",
        "\n",
        "        # Check output sentence\n",
        "        for word in output_sentence.split(' '):\n",
        "            if word not in voc.word2index:\n",
        "                keep_output = False\n",
        "                break\n",
        "\n",
        "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
        "        if keep_input and keep_output:\n",
        "            keep_pairs.append(pair)\n",
        "\n",
        "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
        "    return keep_pairs\n",
        "\n",
        "# Trim voc and pairs\n",
        "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llU9al8P30ht",
        "outputId": "e39dc3ae-19a8-441d-b71d-b3b0d6e0679b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keep_words 7823/18005 = 0.4345\n",
            "Trimmed from 64271 pairs to 53165, 0.8272 of total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data for Models"
      ],
      "metadata": {
        "id": "n_3oxYW_nXCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence (voc, sentence):\n",
        "  return [voc.word2index [word] for word in sentence.split(' ')] + [EOS_token]\n",
        "\n"
      ],
      "metadata": {
        "id": "r2rBM5CHnZuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test the function\n",
        "print(pairs[1][0])\n",
        "indexesFromSentence (voc, pairs [1][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEYBg_dZ7pw7",
        "outputId": "3deb38ff-481d-4379-aaae-67cd49a2c69c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you have my word . as a gentleman\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7, 8, 9, 10, 4, 11, 12, 13, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define some samples for testing\n",
        "inp = []\n",
        "out = []\n",
        "for pair in pairs[:10]:\n",
        "    inp.append(pair[0])\n",
        "    out.append(pair[1])\n",
        "print(inp[3])\n",
        "\n",
        "indexes = [indexesFromSentence(voc, sentence) for sentence in inp]\n",
        "indexes[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpB0B0Ao8HRw",
        "outputId": "27fd5807-87ec-435f-aaff-6dfb106744c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have fun tonight ?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8, 31, 22, 6, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def zeroPadding(l, fillvalue=0):\n",
        "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
        "\n",
        "\n",
        "\n",
        "leng = [len(ind) for ind in indexes]\n",
        "print(max(leng))\n",
        "\n",
        "#Test the function\n",
        "\n",
        "test_result = zeroPadding (indexes)\n",
        "print(len(test_result)) #The max length is now the number of rows or the batch size\n",
        "test_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTEEITG-9GGY",
        "outputId": "e1bd57f2-b2e3-45d4-d403-d4b7f2e9ef4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(3, 7, 16, 8, 33, 35, 42, 47, 50, 58),\n",
              " (4, 8, 4, 31, 34, 36, 2, 7, 51, 2),\n",
              " (2, 9, 2, 22, 4, 37, 0, 48, 52, 0),\n",
              " (0, 10, 0, 6, 4, 38, 0, 40, 6, 0),\n",
              " (0, 4, 0, 2, 4, 7, 0, 45, 2, 0),\n",
              " (0, 11, 0, 0, 2, 39, 0, 49, 0, 0),\n",
              " (0, 12, 0, 0, 0, 40, 0, 6, 0, 0),\n",
              " (0, 13, 0, 0, 0, 41, 0, 2, 0, 0),\n",
              " (0, 2, 0, 0, 0, 4, 0, 0, 0, 0),\n",
              " (0, 0, 0, 0, 0, 2, 0, 0, 0, 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def binaryMatrix(l, value=0):\n",
        "    m = []\n",
        "    for i, seq in enumerate(l):\n",
        "        m.append([])\n",
        "        for token in seq:\n",
        "            if token == PAD_token:\n",
        "                m[i].append(0)\n",
        "            else:\n",
        "                m[i].append(1)\n",
        "    return m\n",
        "\n",
        "binary_result = binaryMatrix(test_result)\n",
        "binary_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap4lmsn095ut",
        "outputId": "177b21d0-ff0e-4271-a343-bae01c63d7d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],\n",
              " [0, 1, 0, 1, 1, 1, 0, 1, 1, 0],\n",
              " [0, 1, 0, 1, 1, 1, 0, 1, 1, 0],\n",
              " [0, 1, 0, 0, 1, 1, 0, 1, 0, 0],\n",
              " [0, 1, 0, 0, 0, 1, 0, 1, 0, 0],\n",
              " [0, 1, 0, 0, 0, 1, 0, 1, 0, 0],\n",
              " [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns padded input sequence tensor and as well as a tensor of lengths for each of the sequences in the batch\n",
        "#of 1st character\n",
        "def inputVar(l, voc):\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, lengths"
      ],
      "metadata": {
        "id": "WhC8GOv3Bh2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns padded target sequence tensor, padding mask, and max target length\n",
        "#of 2nd character\n",
        "def outputVar(l, voc):\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    mask = binaryMatrix(padList)\n",
        "    mask = torch.ByteTensor(mask)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, mask, max_target_len"
      ],
      "metadata": {
        "id": "-dG90ZnuBiTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns all items for a given batch of pairs\n",
        "def batch2TrainData(voc, pair_batch):\n",
        "    # Sort the questions in descending length\n",
        "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
        "    input_batch, output_batch = [], []\n",
        "    for pair in pair_batch:\n",
        "        input_batch.append(pair[0])\n",
        "        output_batch.append(pair[1])\n",
        "    inp, lengths = inputVar(input_batch, voc)\n",
        "    # assert len(inp) == lengths[0]\n",
        "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
        "    return inp, lengths, output, mask, max_target_len"
      ],
      "metadata": {
        "id": "iZs6EAHKB_3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example for validation\n",
        "small_batch_size = 5\n",
        "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
        "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
        "\n",
        "print(\"input_variable:\")\n",
        "print(input_variable)\n",
        "print(\"lengths:\", lengths)\n",
        "print(\"target_variable:\")\n",
        "print(target_variable)\n",
        "print(\"mask:\")\n",
        "print(mask)\n",
        "print(\"max_target_len:\", max_target_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV8PwchlDAGk",
        "outputId": "214da2c9-6fcb-4f40-cd43-a3c633cdf2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variable:\n",
            "tensor([[  50,   25,   94,   50,  787],\n",
            "        [  92,  200,   25,   75,    6],\n",
            "        [   7, 2263,  359,    7,    2],\n",
            "        [ 278,    4,    7, 5936,    0],\n",
            "        [ 159,   76,  558,    6,    0],\n",
            "        [   6,   37,    6,    2,    0],\n",
            "        [ 158,    9,    2,    0,    0],\n",
            "        [  21,  494,    0,    0,    0],\n",
            "        [   4,    4,    0,    0,    0],\n",
            "        [   2,    2,    0,    0,    0]])\n",
            "lengths: tensor([10, 10,  7,  6,  3])\n",
            "target_variable:\n",
            "tensor([[ 213,  124,    7,   25, 5099],\n",
            "        [ 174,  115,   94,  387,    6],\n",
            "        [ 214,   36,  359,  349,    2],\n",
            "        [   4,  147,   83,    4,    0],\n",
            "        [   2,   76,   95,    2,    0],\n",
            "        [   0,  115,    4,    0,    0],\n",
            "        [   0,    6,    2,    0,    0],\n",
            "        [   0,    2,    0,    0,    0]])\n",
            "mask:\n",
            "tensor([[1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 0],\n",
            "        [1, 1, 1, 1, 0],\n",
            "        [0, 1, 1, 0, 0],\n",
            "        [0, 1, 1, 0, 0],\n",
            "        [0, 1, 0, 0, 0]], dtype=torch.uint8)\n",
            "max_target_len: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Models"
      ],
      "metadata": {
        "id": "joJcH3iOk_ev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder"
      ],
      "metadata": {
        "id": "1jGyokuVlKmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = embedding\n",
        "\n",
        "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
        "        # because our input size is a word embedding with number of features == hidden_size\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
        "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
        "\n",
        "    def forward(self, input_seq, input_lengths, hidden=None):\n",
        "        # input_seq: batch of input sentences; shape=(max_length, batch_size)\n",
        "        # input_lengths: list of sentence lengths corresponding to each sentence in the batch\n",
        "        # hidden state, of shape: (n_layers x num_directions, batch_size, hidden_size)\n",
        "\n",
        "        # Convert word indices to embeddings\n",
        "        embedded = self.embedding(input_seq)\n",
        "\n",
        "        # Pack padded batch of sequences for RNN module\n",
        "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
        "\n",
        "        # Forward pass through GRU\n",
        "        outputs, hidden = self.gru(packed, hidden)\n",
        "\n",
        "        # Unpack padding\n",
        "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
        "\n",
        "        # Sum bidirectional GRU outputs\n",
        "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n",
        "\n",
        "        # Return output and final hidden state\n",
        "        return outputs, hidden"
      ],
      "metadata": {
        "id": "BE65zcZITuiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention"
      ],
      "metadata": {
        "id": "qjXSKhi7lNeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Luong attention layer\n",
        "class Attn(torch.nn.Module):\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(Attn, self).__init__()\n",
        "        self.method = method\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    def dot_score(self, hidden, encoder_output):\n",
        "        # Element-Wise Multiply the current target decoder state with the encoder output and sum them\n",
        "        return torch.sum(hidden * encoder_output, dim=2)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # hidden of shape: (1, batch_size, hidden_size)\n",
        "        # encoder_outputs of shape: (max_length, batch_size, hidden_size)\n",
        "        # (1, batch_size, hidden_size) * (max_length, batch_size, hidden_size) = (max_length, batch_size, hidden_size)\n",
        "\n",
        "        # Calculate the attention weights (energies)\n",
        "        attn_energies = self.dot_score(hidden, encoder_outputs)  # (max_length, batch_size)\n",
        "\n",
        "        # Transpose max_length and batch_size dimensions\n",
        "        attn_energies = attn_energies.t()  # (batch_size, max_length)\n",
        "\n",
        "        # Return the softmax normalized probability scores (with added dimension)\n",
        "        return F.softmax(attn_energies, dim=1).unsqueeze(1)  # (batch_size, 1, max_length)"
      ],
      "metadata": {
        "id": "NeuCssjHT1ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder witn Attention"
      ],
      "metadata": {
        "id": "NaDBZDDQVFYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LuongAttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
        "        super(LuongAttnDecoderRNN, self).__init__()\n",
        "        self.attn_model = attn_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Define layers\n",
        "        self.embedding = embedding\n",
        "        self.embedding_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
        "                          dropout=(0 if n_layers == 1 else dropout))\n",
        "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        self.attn = Attn(attn_model, hidden_size)\n",
        "\n",
        "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
        "        # input_step: one time step (one word) of input sequence batch; shape=(1, batch_size)\n",
        "        # last_hidden: final hidden layer of GRU; shape=(n_Layers x num_directions, batch_size, hidden_size)\n",
        "        # encoder_outputs: encoder model's output; shape=(max_length, batch_size, hidden_size)\n",
        "        # Note: we run this one step (word) at a time\n",
        "\n",
        "        # Get embedding of current input word\n",
        "        embedded = self.embedding(input_step)\n",
        "        embedded = self.embedding_dropout(embedded)\n",
        "\n",
        "        # Forward through unidirectional GRU\n",
        "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "\n",
        "        # Calculate attention weights from the current GRU output\n",
        "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "\n",
        "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
        "        # (batch_size,1, max_length) bmm with (batch_size, max_length, hidden) = (batch_size,1, hidden)\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
        "\n",
        "        # Concatenate weighted context vector and GRU output\n",
        "        rnn_output = rnn_output.squeeze(0)\n",
        "        context = context.squeeze(1)\n",
        "        concat_input = torch.cat((rnn_output, context), 1)\n",
        "        concat_output = torch.tanh(self.concat(concat_input))\n",
        "\n",
        "        # Predict next word using Luong eq. 6\n",
        "        output = self.out(concat_output)\n",
        "        output = F.softmax(output, dim=1)\n",
        "\n",
        "        # Return output and final hidden state\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "        #output: softmax normalized tensor giving probabilities of each word being the correct next word in the decoded sequence\n",
        "        #shape=(batch_size, voc.num_words)\n",
        "        # hidden: final hidden state of GRU; shape=(n_layers x num_directions, batch_size, hidden_size)"
      ],
      "metadata": {
        "id": "hBat2nMQWCdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss fct & single training iteration"
      ],
      "metadata": {
        "id": "_Nb9ajdNlTuw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Masked loss"
      ],
      "metadata": {
        "id": "d5Kwt5iJlaGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def maskNLLLoss(decoder_out, target, mask):\n",
        "    # Convert mask to boolean tensor (CRITICAL)\n",
        "    bool_mask = mask.bool()\n",
        "    nTotal = bool_mask.sum().item()  # Number of non-padded tokens\n",
        "\n",
        "    # Handle empty mask case (no valid tokens)\n",
        "    if nTotal == 0:\n",
        "        return torch.tensor(0.0, device=decoder_out.device), 0\n",
        "\n",
        "    # Reshape target for gathering\n",
        "    target = target.view(-1, 1)\n",
        "    gathered_tensor = torch.gather(decoder_out, 1, target)\n",
        "\n",
        "    # Calculate loss per token\n",
        "    crossEntropy = -torch.log(gathered_tensor.squeeze(1))\n",
        "\n",
        "    # Apply boolean mask and calculate mean loss\n",
        "    loss = crossEntropy.masked_select(bool_mask).mean()\n",
        "\n",
        "    return loss, nTotal"
      ],
      "metadata": {
        "id": "Z3CwPltyYatB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Single training iteration"
      ],
      "metadata": {
        "id": "dGpizC0-laxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing what's happening in one iteration. Only run this for visualization.\n",
        "small_batch_size = 5\n",
        "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
        "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
        "\n",
        "print(\"input_variable shape:\", input_variable.shape)\n",
        "print(\"lengths shape:\", lengths.shape)\n",
        "print(\"target_variable shape:\", target_variable.shape)\n",
        "print(\"mask shape:\", mask.shape)\n",
        "print(\"max_target_len:\", max_target_len)\n",
        "\n",
        "# Define the parameters\n",
        "hidden_size = 500\n",
        "encoder_n_layers = 2\n",
        "decoder_n_layers = 2\n",
        "dropout = 0.1\n",
        "attn_model = 'dot'\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "\n",
        "# Define the encoder and Decoder\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "# Ensure dropout layers are in train mode\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "\n",
        "# Initialize optimizers\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.0001)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.0001)\n",
        "encoder_optimizer.zero_grad()\n",
        "decoder_optimizer.zero_grad()\n",
        "\n",
        "input_variable = input_variable.to(device)\n",
        "lengths = lengths.to(device)\n",
        "target_variable = target_variable.to(device)\n",
        "mask = mask.to(device)\n",
        "\n",
        "loss = 0\n",
        "print_losses = []\n",
        "n_totals = 0\n",
        "\n",
        "encoder_outputs, encoder_hidden = encoder(input_variable, lengths.cpu())\n",
        "print(\"Encoder Outputs Shape:\", encoder_outputs.shape)\n",
        "print(\"Last Encoder Hidden Shape\", encoder_hidden.shape)\n",
        "\n",
        "decoder_input = torch.LongTensor([[SOS_token for _ in range(small_batch_size)]])\n",
        "decoder_input = decoder_input.to(device)\n",
        "print(\"Initial Decoder Input Shape:\", decoder_input.shape)\n",
        "print(decoder_input)\n",
        "\n",
        "# Set initial decoder hidden state to the encoder's final hidden state\n",
        "decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "print(\"Initial Decoder hidden state shape:\", decoder_hidden.shape)\n",
        "print(\"\\n\")\n",
        "print(\"---------------------------------------------\")\n",
        "print(\"Now Let's look what's happening in every timestep of the GRU!\")\n",
        "print(\"---------------------------------------------\")\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "# Assume we are using Teacher Forcing\n",
        "for t in range(max_target_len):\n",
        "    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "    print(\"Decoder Output Shape:\", decoder_output.shape)\n",
        "    print(\"Decoder Hidden Shape:\", decoder_hidden.shape)\n",
        "\n",
        "    # Teacher forcing: next input is current target\n",
        "    decoder_input = target_variable[t].view(1, -1)\n",
        "    print(\"The target variable at the current timestep before reshaping:\", target_variable[t])\n",
        "    print(\"The target variable at the current timestep shape before reshaping:\", target_variable[t].shape)\n",
        "    print(\"The Decoder input shape (reshape the target variable):\", decoder_input.shape)\n",
        "\n",
        "    # Calculate and accumulate loss\n",
        "    print(\"The mask at the current timestep:\", mask[t])\n",
        "    print(\"The mask at the current timestep shape:\", mask[t].shape)\n",
        "    mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "    print(\"Mask Loss:\", mask_loss)\n",
        "    print(\"Total:\", nTotal)\n",
        "    loss += mask_loss\n",
        "    print_losses.append(mask_loss.item() * nTotal)\n",
        "    n_totals += nTotal\n",
        "\n",
        "    print(n_totals)\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    returned_loss = sum(print_losses) / n_totals\n",
        "    print(\"Returned Loss: \", returned_loss)\n",
        "    print(\"\\n\")\n",
        "    print(\"----------------ONE TIMESTEP----------------\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58QvYqZkZyfq",
        "outputId": "7a885f96-4ee0-420a-a633-8c9fd333f7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variable shape: torch.Size([8, 5])\n",
            "lengths shape: torch.Size([5])\n",
            "target_variable shape: torch.Size([10, 5])\n",
            "mask shape: torch.Size([10, 5])\n",
            "max_target_len: 10\n",
            "Encoder Outputs Shape: torch.Size([8, 5, 500])\n",
            "Last Encoder Hidden Shape torch.Size([4, 5, 500])\n",
            "Initial Decoder Input Shape: torch.Size([1, 5])\n",
            "tensor([[1, 1, 1, 1, 1]], device='cuda:0')\n",
            "Initial Decoder hidden state shape: torch.Size([2, 5, 500])\n",
            "\n",
            "\n",
            "---------------------------------------------\n",
            "Now Let's look what's happening in every timestep of the GRU!\n",
            "---------------------------------------------\n",
            "\n",
            "\n",
            "Decoder Output Shape: torch.Size([5, 7826])\n",
            "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
            "The target variable at the current timestep before reshaping: tensor([ 25,  94, 318, 100, 124], device='cuda:0')\n",
            "The target variable at the current timestep shape before reshaping: torch.Size([5])\n",
            "The Decoder input shape (reshape the target variable): torch.Size([1, 5])\n",
            "The mask at the current timestep: tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
            "The mask at the current timestep shape: torch.Size([5])\n",
            "Mask Loss: tensor(8.9311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Total: 5\n",
            "5\n",
            "Returned Loss:  8.931086540222168\n",
            "\n",
            "\n",
            "----------------ONE TIMESTEP----------------\n",
            "\n",
            "\n",
            "Decoder Output Shape: torch.Size([5, 7826])\n",
            "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
            "The target variable at the current timestep before reshaping: tensor([200,  27,   4, 115,   7], device='cuda:0')\n",
            "The target variable at the current timestep shape before reshaping: torch.Size([5])\n",
            "The Decoder input shape (reshape the target variable): torch.Size([1, 5])\n",
            "The mask at the current timestep: tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
            "The mask at the current timestep shape: torch.Size([5])\n",
            "Mask Loss: tensor(8.9788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Total: 5\n",
            "10\n",
            "Returned Loss:  8.954922676086426\n",
            "\n",
            "\n",
            "----------------ONE TIMESTEP----------------\n",
            "\n",
            "\n",
            "Decoder Output Shape: torch.Size([5, 7826])\n",
            "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
            "The target variable at the current timestep before reshaping: tensor([278, 542,   2,  45,  24], device='cuda:0')\n",
            "The target variable at the current timestep shape before reshaping: torch.Size([5])\n",
            "The Decoder input shape (reshape the target variable): torch.Size([1, 5])\n",
            "The mask at the current timestep: tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
            "The mask at the current timestep shape: torch.Size([5])\n",
            "Mask Loss: tensor(8.9498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Total: 5\n",
            "15\n",
            "Returned Loss:  8.953217188517252\n",
            "\n",
            "\n",
            "----------------ONE TIMESTEP----------------\n",
            "\n",
            "\n",
            "Decoder Output Shape: torch.Size([5, 7826])\n",
            "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
            "The target variable at the current timestep before reshaping: tensor([50,  6,  0,  6, 50], device='cuda:0')\n",
            "The target variable at the current timestep shape before reshaping: torch.Size([5])\n",
            "The Decoder input shape (reshape the target variable): torch.Size([1, 5])\n",
            "The mask at the current timestep: tensor([1, 1, 0, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
            "The mask at the current timestep shape: torch.Size([5])\n",
            "Mask Loss: tensor(8.9657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Total: 4\n",
            "19\n",
            "Returned Loss:  8.955835141633687\n",
            "\n",
            "\n",
            "----------------ONE TIMESTEP----------------\n",
            "\n",
            "\n",
            "Decoder Output Shape: torch.Size([5, 7826])\n",
            "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
            "The target variable at the current timestep before reshaping: tensor([25,  2,  0,  2,  4], device='cuda:0')\n",
            "The target variable at the current timestep shape before reshaping: torch.Size([5])\n",
            "The Decoder input shape (reshape the target variable): torch.Size([1, 5])\n",
            "The mask at the current timestep: tensor([1, 1, 0, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
            "The mask at the current timestep shape: torch.Size([5])\n",
            "Mask Loss: tensor(8.9644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Total: 4\n",
            "23\n",
            "Returned Loss:  8.95732357191003\n",
            "\n",
            "\n",
            "----------------ONE TIMESTEP----------------\n",
            "\n",
            "\n",
            "Decoder Output Shape: torch.Size([5, 7826])\n",
            "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
            "The target variable at the current timestep before reshaping: tensor([94,  0,  0,  0, 25], device='cuda:0')\n",
            "The target variable at the current timestep shape before reshaping: torch.Size([5])\n",
            "The Decoder input shape (reshape the target variable): torch.Size([1, 5])\n",
            "The mask at the current timestep: tensor([1, 0, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n",
            "The mask at the current timestep shape: torch.Size([5])\n",
            "Mask Loss: tensor(8.9588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Total: 2\n",
            "25\n",
            "Returned Loss:  8.9574422454834\n",
            "\n",
            "\n",
            "----------------ONE TIMESTEP----------------\n",
            "\n",
            "\n",
            "Decoder Output Shape: torch.Size([5, 7826])\n",
            "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
            "The target variable at the current timestep before reshaping: tensor([  4,   0,   0,   0, 200], device='cuda:0')\n",
            "The target variable at the current timestep shape before reshaping: torch.Size([5])\n",
            "The Decoder input shape (reshape the target variable): torch.Size([1, 5])\n",
            "The mask at the current timestep: tensor([1, 0, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n",
            "The mask at the current timestep shape: torch.Size([5])\n",
            "Mask Loss: tensor(9.0089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Total: 2\n",
            "27\n",
            "Returned Loss:  8.9612567336471\n",
            "\n",
            "\n",
            "----------------ONE TIMESTEP----------------\n",
            "\n",
            "\n",
            "Decoder Output Shape: torch.Size([5, 7826])\n",
            "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
            "The target variable at the current timestep before reshaping: tensor([   2,    0,    0,    0, 6690], device='cuda:0')\n",
            "The target variable at the current timestep shape before reshaping: torch.Size([5])\n",
            "The Decoder input shape (reshape the target variable): torch.Size([1, 5])\n",
            "The mask at the current timestep: tensor([1, 0, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n",
            "The mask at the current timestep shape: torch.Size([5])\n",
            "Mask Loss: tensor(8.9991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Total: 2\n",
            "29\n",
            "Returned Loss:  8.963864359362372\n",
            "\n",
            "\n",
            "----------------ONE TIMESTEP----------------\n",
            "\n",
            "\n",
            "Decoder Output Shape: torch.Size([5, 7826])\n",
            "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
            "The target variable at the current timestep before reshaping: tensor([ 0,  0,  0,  0, 66], device='cuda:0')\n",
            "The target variable at the current timestep shape before reshaping: torch.Size([5])\n",
            "The Decoder input shape (reshape the target variable): torch.Size([1, 5])\n",
            "The mask at the current timestep: tensor([0, 0, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n",
            "The mask at the current timestep shape: torch.Size([5])\n",
            "Mask Loss: tensor(8.9548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Total: 1\n",
            "30\n",
            "Returned Loss:  8.963562965393066\n",
            "\n",
            "\n",
            "----------------ONE TIMESTEP----------------\n",
            "\n",
            "\n",
            "Decoder Output Shape: torch.Size([5, 7826])\n",
            "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
            "The target variable at the current timestep before reshaping: tensor([0, 0, 0, 0, 2], device='cuda:0')\n",
            "The target variable at the current timestep shape before reshaping: torch.Size([5])\n",
            "The Decoder input shape (reshape the target variable): torch.Size([1, 5])\n",
            "The mask at the current timestep: tensor([0, 0, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n",
            "The mask at the current timestep shape: torch.Size([5])\n",
            "Mask Loss: tensor(8.9846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Total: 1\n",
            "31\n",
            "Returned Loss:  8.964241027832031\n",
            "\n",
            "\n",
            "----------------ONE TIMESTEP----------------\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training function"
      ],
      "metadata": {
        "id": "W0SqofUAliGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
        "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
        "\n",
        "    # Zero gradients\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    # Set device options\n",
        "    input_variable = input_variable.to(device)\n",
        "\n",
        "    target_variable = target_variable.to(device)\n",
        "    mask = mask.to(device)\n",
        "\n",
        "    # Initialize variables\n",
        "    loss = 0\n",
        "    print_losses = []\n",
        "    n_totals = 0\n",
        "\n",
        "    # Forward pass through encoder\n",
        "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
        "\n",
        "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
        "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
        "    decoder_input = decoder_input.to(device)\n",
        "\n",
        "    # Set initial decoder hidden state to the encoder's final hidden state\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "\n",
        "    # Determine if we are using teacher forcing this iteration\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    # Forward batch of sequences through decoder one time step at a time\n",
        "    if use_teacher_forcing:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            # Teacher forcing: next input is current target\n",
        "            decoder_input = target_variable[t].view(1, -1)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "    else:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            # No teacher forcing: next input is decoder's own current output\n",
        "            _, topi = decoder_output.topk(1)\n",
        "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
        "            decoder_input = decoder_input.to(device)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "\n",
        "    # Perform backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip gradients: gradients are modified in place\n",
        "    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "\n",
        "    # Adjust model weights\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    # With this safe division:\n",
        "    if n_totals == 0:\n",
        "        return 0.0  # Avoid division by zero\n",
        "    else:\n",
        "        return sum(print_losses) / n_totals"
      ],
      "metadata": {
        "id": "ymLy8UeydOiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# training iterations"
      ],
      "metadata": {
        "id": "wArsUupGfXRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training parameters\n",
        "model_name = 'chatbot_model'\n",
        "n_iteration = 5000  # Number of training steps\n",
        "batch_size = 64\n",
        "clip = 50.0  # Gradient clipping threshold\n",
        "teacher_forcing_ratio = 1.0  # Start with full teacher forcing\n",
        "learning_rate = 0.0001\n",
        "print_every = 100  # Print loss every N batches\n",
        "\n",
        "# Initialize models and optimizers\n",
        "hidden_size = 500\n",
        "encoder_n_layers = 2\n",
        "decoder_n_layers = 2\n",
        "dropout = 0.1\n",
        "attn_model = 'dot'\n",
        "\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * 5.0)\n",
        "\n"
      ],
      "metadata": {
        "id": "MB0f50QFgEO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer,\n",
        "               decoder_optimizer, embedding, n_iteration, batch_size, clip,\n",
        "               print_every=100, plot_every=100, save_every=500):\n",
        "    # Initialize metrics tracking\n",
        "    start_iteration = 1\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0   # Reset every plot_every\n",
        "    all_losses = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"Starting training for {n_iteration} iterations...\")\n",
        "    print(f\"Batch size: {batch_size}, Print every: {print_every}, Save every: {save_every}\")\n",
        "\n",
        "    for iteration in range(start_iteration, n_iteration + 1):\n",
        "        # Get training batch\n",
        "        training_batch = batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
        "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
        "\n",
        "        lengths = lengths.cpu()\n",
        "\n",
        "        # Run training iteration\n",
        "        loss = train(input_variable, lengths, target_variable, mask, max_target_len,\n",
        "                     encoder, decoder, embedding, encoder_optimizer, decoder_optimizer,\n",
        "                     batch_size, clip)\n",
        "\n",
        "        # Update tracking metrics\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "        all_losses.append(loss)\n",
        "\n",
        "        # Calculate progress metrics\n",
        "        time_elapsed = time.time() - start_time\n",
        "        iterations_done = iteration - start_iteration + 1\n",
        "        time_per_iter = time_elapsed / iterations_done\n",
        "        remaining_iters = n_iteration - iteration\n",
        "        eta_seconds = remaining_iters * time_per_iter\n",
        "        eta_str = time.strftime(\"%H:%M:%S\", time.gmtime(eta_seconds))\n",
        "\n",
        "        # Print progress\n",
        "        if iteration % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "\n",
        "            progress_percent = iteration / n_iteration * 100\n",
        "            print(f\"[{time.strftime('%H:%M:%S')}] Iteration: {iteration}/{n_iteration} ({progress_percent:.1f}%)\")\n",
        "            print(f\"  Loss: {print_loss_avg:.4f} | ETA: {eta_str}\")\n",
        "            print(f\"  Avg time per iter: {time_per_iter:.2f}s | Elapsed: {time_elapsed/60:.1f}min\")\n",
        "\n",
        "            # Optional: Print sample prediction\n",
        "            if iteration % (print_every * 5) == 0:\n",
        "                sample_prediction(encoder, decoder, voc, pairs)\n",
        "\n",
        "        # Update plot\n",
        "        if iteration % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_loss_total = 0\n",
        "            clear_output(wait=True)\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.plot(all_losses, label='Training Loss')\n",
        "            plt.xlabel('Iterations')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.title(f'Training Progress (Current Loss: {plot_loss_avg:.4f})')\n",
        "            plt.grid(True)\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "        # Save checkpoint\n",
        "        if iteration % save_every == 0:\n",
        "            save_path = f\"{model_name}_{iteration}.pth\"\n",
        "            torch.save({\n",
        "                'iteration': iteration,\n",
        "                'encoder': encoder.state_dict(),\n",
        "                'decoder': decoder.state_dict(),\n",
        "                'encoder_optimizer': encoder_optimizer.state_dict(),\n",
        "                'decoder_optimizer': decoder_optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "                'voc': voc\n",
        "            }, save_path)\n",
        "            print(f\"Saved checkpoint to {save_path}\")\n",
        "\n",
        "    # Save final model\n",
        "    final_save_path = f\"{model_name}_final.pth\"\n",
        "    torch.save({\n",
        "        'encoder': encoder.state_dict(),\n",
        "        'decoder': decoder.state_dict(),\n",
        "        'voc': voc\n",
        "    }, final_save_path)\n",
        "    print(f\"Training complete! Final model saved to {final_save_path}\")\n",
        "\n",
        "    return all_losses"
      ],
      "metadata": {
        "id": "PUwuK4D9keQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for the metrics"
      ],
      "metadata": {
        "id": "Kao_B0Ma6HFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_prediction(encoder, decoder, voc, pairs, n=3):\n",
        "    \"\"\"Generate sample predictions during training\"\"\"\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    print(\"\\nSample Predictions:\")\n",
        "    for _ in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        input_sentence = pair[0]\n",
        "        target_sentence = pair[1]\n",
        "\n",
        "        # Format input sentence\n",
        "        input_tokens = [word for word in input_sentence.split(' ') if word]\n",
        "        input_indexes = [voc.word2index[word] for word in input_tokens]\n",
        "        input_batch = torch.LongTensor([input_indexes]).transpose(0, 1).to(device)\n",
        "        lengths = torch.tensor([len(input_indexes)]).cpu()\n",
        "\n",
        "        # Generate response\n",
        "        response = generate_response(encoder, decoder, voc, input_batch, lengths)\n",
        "\n",
        "        print(f\"Input: {input_sentence}\")\n",
        "        print(f\"Target: {target_sentence}\")\n",
        "        print(f\"Model: {response}\\n\")\n",
        "\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "\n",
        "\n",
        "def generate_response(encoder, decoder, voc, input_batch, input_length, max_length=MAX_LENGTH):\n",
        "    \"\"\"Generate response from input sequence\"\"\"\n",
        "    # Forward pass through encoder\n",
        "    encoder_outputs, encoder_hidden = encoder(input_batch, input_length)\n",
        "\n",
        "    # Create decoder input\n",
        "    decoder_input = torch.LongTensor([[SOS_token]]).to(device)\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "\n",
        "    decoded_words = []\n",
        "    for _ in range(max_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "\n",
        "        # Choose top word\n",
        "        _, topi = decoder_output.topk(1)\n",
        "        ni = topi.squeeze().item()\n",
        "\n",
        "        if ni == EOS_token:\n",
        "            break\n",
        "        else:\n",
        "            decoded_words.append(voc.index2word[ni])\n",
        "\n",
        "        # Next input is current output\n",
        "        decoder_input = torch.LongTensor([[ni]]).to(device)\n",
        "\n",
        "    return ' '.join(decoded_words)"
      ],
      "metadata": {
        "id": "TgZRJ49XmCfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "start training"
      ],
      "metadata": {
        "id": "zMblaCTs6Is_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "model_name = 'chatbot'\n",
        "n_iteration = 10000 #save model each 1000 iterations\n",
        "batch_size = 64\n",
        "clip = 50.0\n",
        "\n",
        "\n",
        "# Start training\n",
        "loss_history = trainIters(\n",
        "    model_name=model_name,\n",
        "    voc=voc,\n",
        "    pairs=pairs,\n",
        "    encoder=encoder,\n",
        "    decoder=decoder,\n",
        "    encoder_optimizer=encoder_optimizer,\n",
        "    decoder_optimizer=decoder_optimizer,\n",
        "    embedding=embedding,\n",
        "    n_iteration=n_iteration,\n",
        "    batch_size=batch_size,\n",
        "    clip=clip,\n",
        "    print_every=100,    # Print metrics every 100 iterations\n",
        "    plot_every=200,     # Update plot every 200 iterations\n",
        "    save_every=1000     # Save checkpoint every 1000 iterations\n",
        ")\n",
        "\n",
        "# ETA 8min"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "17uAZmFgmMlN",
        "outputId": "7394d98f-23b5-4f0f-a11f-df2658193779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0EAAAHWCAYAAACxAYILAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAlLFJREFUeJzs3XdYU9cbB/BvEvbeIoqAoKIoLhy49161Vqu2jtZOrVq7tHY46mj7q7Vqa22t2mrVuttaF+4t4t6KICCKiMpQVkju7w/MhZAACQaSyPfzPD7lnnvuvSfhVPPmnPMeiSAIAoiIiIiIiCoJqbEbQEREREREVJEYBBERERERUaXCIIiIiIiIiCoVBkFERERERFSpMAgiIiIiIqJKhUEQERERERFVKgyCiIiIiIioUmEQRERERERElQqDICIiIiIiqlQYBBGRSRo1ahT8/f3LdO20adMgkUgM2yAqV5GRkbCyskJcXJyxm0JUZjt27ICDgwPu379v7KYQUSkYBBGRXiQSiU5/9u/fb+ymGsWoUaPU3gcnJyc0bNgQ3333HXJycozdPJM1depUDB06FH5+fhrnNm/ejJ49e8LDwwNWVlbw8fHB4MGDsXfvXiO01HBmz56NLVu26FT31q1bkEgk+N///le+jSond+/exeTJk9GxY0c4Ojrq/XfE5s2b0b17d/j4+MDa2hrVq1fHoEGDcPHiRbV6Dx48wLfffot27drB09MTLi4uaNmyJf766y+t971x4wZefvllVK9eHXZ2dggODsaMGTOQmZmpVm/27Nlo2bIlPD09YWNjg1q1amHixIkawU6PHj0QFBSEOXPm6PzaiMg4JIIgCMZuBBGZj1WrVqkd//HHH4iIiMDKlSvVyrt27YoqVaqU+TlyuRxKpRLW1tZ6X5uXl4e8vDzY2NiU+fllNWrUKKxduxZLly4FAKSmpmLjxo3Yv38/hgwZgrVr11Z4m0zd2bNn0bhxYxw9ehTh4eFiuSAIeO2117BixQo0btwYgwYNgre3N+7evYvNmzfj1KlTOHLkCFq1amXE1pedg4MDBg0ahBUrVpRa99atWwgICMC3336LDz/8sPwbZ2D79+9Hx44dUatWLXh4eODYsWPYt28fOnTooNP1M2bMwOXLl9G4cWN4eHggKSkJy5Ytw927d3Hs2DE0bNgQALB161YMHDgQvXr1QseOHWFhYYGNGzdi3759+OKLLzB9+nTxngkJCQgNDYWzszPefvttuLm54dixY1ixYgX69euHv//+W6z74osvwtPTE8HBwXB0dMSVK1fw66+/wsvLC2fPnoW9vb1Yd/Hixfjwww+RlJQER0dHw7yBRGR4AhHRMxg7dqygy18lT548qYDWGN/IkSMFe3t7tTKFQiGEhYUJAITExESt1ymVSiEzM7MimigIgmn9PsaPHy/UqFFDUCqVauXffvutAECYOHGixjlBEIQ//vhDOHHixDM/v6T3PisrS1AoFM/8DG3s7e2FkSNH6lQ3NjZWACB8++235dKW8paeni48ePBAEARBWL9+vQBA2Ldv3zPdMykpSbCwsBDeeustsSwmJka4deuWWj2lUil06tRJsLa2Fh4/fiyWz5o1SwAgXLx4Ua3+iBEjBADCw4cPS3z+hg0bBADCmjVr1Mrv3bsnyGQy4bfffivrSyOiCsDpcERkcB06dED9+vVx6tQptGvXDnZ2dvj0008BAH///Td69+4tTmsJDAzEzJkzoVAo1O5RdE1Q4elAv/zyCwIDA2FtbY1mzZrh5MmTatdqWxMkkUgwbtw4bNmyBfXr14e1tTVCQkKwY8cOjfbv378fYWFhsLGxQWBgIJYsWfJM64ykUqn4jfetW7cAAP7+/ujTpw927tyJsLAw2NraYsmSJQCAmJgYvPTSS3Bzc4OdnR1atmyJ//77T+O+cXFx6NevH+zt7eHl5YX3338fO3fu1JhqVNLvIycnB19++SWCgoJgbW0NX19ffPzxxxpT9yIiItCmTRu4uLjAwcEBderUEe+hsnDhQoSEhMDOzg6urq4ICwvD6tWrS31/tmzZgk6dOqm9v1lZWZgzZw6Cg4Pxv//9T+t7/+qrr6J58+YAil8HtmLFCkgkEvF9B4p/7/fv3w+JRIK1a9fis88+Q7Vq1WBnZ4f09HQAwIkTJ9CjRw84OzvDzs4O7du3x5EjR9Sep2pHdHQ0Ro0aBRcXFzg7O2P06NFqU6wkEgmePHmC33//XZw6OWrUqFLfq9IkJyfj9ddfR5UqVWBjY4OGDRvi999/16i3du1aNG3aFI6OjnByckKDBg3www8/iOflcjmmT5+OWrVqwcbGBu7u7mjTpg0iIiLU6ly9ehV3794ttV2Ojo5wc3N75tdXmJeXF+zs7JCamiqWBQQEaEyplEgkGDBgAHJychATEyOWq36vRUesq1atCqlUCisrqxKfr/r7qfDzVe0KDQ1VG0kiItNjYewGENHz6cGDB+jZsydefvllvPLKK+IHjRUrVsDBwQGTJk2Cg4MD9u7diy+++ALp6en49ttvS73v6tWrkZGRgbfeegsSiQTffPMNBg4ciJiYGFhaWpZ47eHDh7Fp0ya8++67cHR0xIIFC/Diiy8iPj4e7u7uAIAzZ86gR48eqFq1KqZPnw6FQoEZM2bA09Pzmd6PmzdvAoD4HAC4du0ahg4dirfeegtvvPEG6tSpg3v37qFVq1bIzMzE+PHj4e7ujt9//x39+vXDhg0b8MILLwAAnjx5gk6dOuHu3buYMGECvL29sXr1auzbt0/r87X9PpRKJfr164fDhw/jzTffRN26dXHhwgV8//33uH79urhe5dKlS+jTpw9CQ0MxY8YMWFtbIzo6Wi0A+PXXXzF+/HgMGjQIEyZMQHZ2Ns6fP48TJ05g2LBhxb4viYmJiI+PR5MmTdTKDx8+jIcPH2LixImQyWRles9Lou29V5k5cyasrKzw4YcfIicnB1ZWVti7dy969uyJpk2b4ssvv4RUKsXy5cvRqVMnHDp0SAzGVAYPHoyAgADMmTMHp0+fxtKlS+Hl5YWvv/4aALBy5UqMGTMGzZs3x5tvvgkACAwMfKbXlJWVhQ4dOiA6Ohrjxo1DQEAA1q9fj1GjRiE1NRUTJkwAkB/QDh06FJ07dxbbc+XKFRw5ckSsM23aNMyZM0dsY3p6OqKionD69Gl07doVQP7vrm7duhg5cqROU/oMITU1FXK5HElJSZg/fz7S09PRuXPnUq9LSkoCAHh4eIhlHTp0wNdff43XX38d06dPh7u7O44ePYrFixdj/PjxalPcgPzpmQ8ePEBeXh5u3LiByZMnQyaTaZ3S17RpU53XexGRkRh7KIqIzJu26XDt27cXAAg///yzRn1t047eeustwc7OTsjOzhbLRo4cKfj5+YnHqulA7u7uatNU/v77bwGA8O+//4plX375pUabAAhWVlZCdHS0WHbu3DkBgLBw4UKxrG/fvoKdnZ3atLUbN24IFhYWOk37U02Hu3//vnD//n0hOjpamD17tiCRSITQ0FCxnp+fnwBA2LFjh9r1EydOFAAIhw4dEssyMjKEgIAAwd/fX5ya9d133wkAhC1btoj1srKyhODgYI2pRsX9PlauXClIpVK1ZwmCIPz8888CAOHIkSOCIAjC999/LwAQ7t+/X+zr7t+/vxASElLq+1PU7t27NX5/giAIP/zwgwBA2Lx5s0730fY7FwRBWL58uQBAiI2NFcuKe+/37dsnABBq1qyp1k+VSqVQq1YtoXv37mrT8jIzM4WAgACha9euGu147bXX1O79wgsvCO7u7mplhp4ON3/+fAGAsGrVKrEsNzdXCA8PFxwcHIT09HRBEARhwoQJgpOTk5CXl1fsvRo2bCj07t1bpzbp+hpUnmU6XJ06dQQAAgDBwcFB+Oyzz0qdrvjgwQPBy8tLaNu2rca5mTNnCra2tuI9AQhTp07Vep+7d++q1atevbrw119/aa07e/ZsAYBw7949vV8jEVUMTocjonJhbW2N0aNHa5Tb2tqKP2dkZCAlJQVt27ZFZmYmrl69Wup9hwwZAldXV/G4bdu2AKA2zaU4Xbp0Ufu2PTQ0FE5OTuK1CoUCu3fvxoABA+Dj4yPWCwoKQs+ePUu9v8qTJ0/g6ekJT09PBAUF4dNPP0V4eDg2b96sVi8gIADdu3dXK9u2bRuaN2+ONm3aiGUODg548803cevWLVy+fBlAfireatWqoV+/fmI9GxsbvPHGG1rbpO33sX79etStWxfBwcFISUkR/3Tq1AkAxFElFxcXAPlTGZVKpdb7u7i44Pbt2xpTE0vz4MEDAFD7nQIFU5XKa2G5tvdeZeTIkWr99OzZs7hx4waGDRuGBw8eiO/TkydP0LlzZxw8eFDjfXn77bfVjtu2bYsHDx6Ir6s8bNu2Dd7e3hg6dKhYZmlpifHjx+Px48c4cOAAgPzf1ZMnT9SmthXl4uKCS5cu4caNG8XW8ff3hyAIFTYKBADLly/Hjh078NNPP6Fu3brIysrSmEpbmFKpxPDhw5GamoqFCxdqnPf390e7du3wyy+/YOPGjXjttdcwe/ZsLFq0SKOum5sbIiIi8O+//2LGjBnw8PDA48ePtT5X1Z9TUlLK+EqJqLxxOhwRlYtq1appnVN/6dIlfPbZZ9i7d6/GB8K0tLRS71ujRg21Y9WHjUePHul9rep61bXJycnIyspCUFCQRj1tZcWxsbHBv//+CyA/+AgICED16tU16gUEBGiUxcXFoUWLFhrldevWFc/Xr18fcXFxCAwM1FgHU1w7tf0+bty4gStXrhQ71S85ORlAfuC5dOlSjBkzBpMnT0bnzp0xcOBADBo0CFJp/ndpn3zyCXbv3o3mzZsjKCgI3bp1w7Bhw9C6dWut9y5KKJKo1MnJCUB+oFwetL33xZ1TBQIjR44s9pq0tDS1QK6kfqp6bYYWFxeHWrVqib8TlcJ9BwDeffddrFu3Dj179kS1atXQrVs3DB48GD169BCvmTFjBvr374/atWujfv366NGjB1599VWEhoaWS9t1VTh74Msvvyy+tuJSh7/33nvYsWMH/vjjDzGDnMratWvx5ptv4vr16+L/nwMHDoRSqcQnn3yCoUOHqk1ftbKyQpcuXQAAffr0QefOndG6dWt4eXmhT58+avdW9WfuV0ZkuhgEEVG5KPxNukpqairat28PJycnzJgxA4GBgbCxscHp06fxySefFDvKUFhx60OKfog29LX6kMlk4oelkmh7j8qLtmcplUo0aNAA8+bN03qNr6+veO3Bgwexb98+/Pfff9ixYwf++usvdOrUCbt27YJMJkPdunVx7do1bN26FTt27MDGjRvx008/aaQlLkr1IbNoEBscHAwAuHDhAgYMGFDq6yvuw2ZxowQlvfdFz6n65bfffotGjRppvcbBwUHtuKL6Wlmo0jrv3LkT27dvx/bt27F8+XKMGDFCTKLQrl073Lx5E3///Td27dqFpUuX4vvvv8fPP/+MMWPGGPkV5HN1dUWnTp3w559/ag2Cpk+fjp9++glz587Fq6++qnH+p59+QuPGjTW+oOjXrx9WrFiBM2fOlPj/catWrVC1alX8+eefGkGQqj8XXoNERKaFQRARVZj9+/fjwYMH2LRpE9q1ayeWx8bGGrFVBby8vGBjY4Po6GiNc9rKyoOfnx+uXbumUa6aKqjKfOXn54fLly9DEAS1AECfdgYGBuLcuXPo3Llzqd9YS6VSdO7cGZ07d8a8efMwe/ZsTJ06Ffv27RM/KNrb22PIkCEYMmQIcnNzMXDgQMyaNQtTpkwpds8mVbBTtA+0adMGrq6uWLNmDT799NNSkyOoRlpSU1PF6XtAwejHs1BNoXRyctIpuNWVoUcJ/Pz8cP78eSiVSrXRoKJ9B8gf1ejbty/69u0LpVKJd999F0uWLMHnn38ujia6ublh9OjRGD16NB4/fox27dph2rRpJhMEAfnJILSNIP/444+YNm0aJk6ciE8++UTrtffu3dOYhgnkZ70D8vcbK012drbW58fGxsLDw+OZE6oQUfnhmiAiqjCqD7KFvw3Pzc3FTz/9ZKwmqVGN4GzZsgV37twRy6Ojo7F9+/YKaUOvXr0QGRmJY8eOiWVPnjzBL7/8An9/f9SrVw8A0L17dyQmJuKff/4R62VnZ+PXX3/V+VmDBw9GYmKi1muysrLw5MkTAMDDhw81zqtGRFSptFVre1SsrKxQr149CIIgfqjUplq1avD19UVUVJRauZ2dHT755BNcuXIFn3zyidYRlFWrViEyMhJAQaBy8OBB8bwqBfWzatq0KQIDA/G///1P6xqQ+/fvl+m+9vb2GumVn0WvXr2QlJSEv/76SyzLy8vDwoUL4eDggPbt2wPQ/F1JpVJxmltxv08HBwcEBQWppU7XJ0W2PuLj4zXWB6qmZhZ269Yt7NmzB2FhYWrlf/31F8aPH4/hw4cXO8oJALVr18aZM2dw/fp1tfI1a9aovSdPnjxRS2+usnHjRjx69Ejj+QBw6tQptal7RGR6OBJERBWmVatWcHV1xciRIzF+/HhIJBKsXLnSJKYIqUybNg27du1C69at8c4770ChUGDRokWoX78+zp49W+7Pnzx5MtasWYOePXti/PjxcHNzw++//47Y2Fhs3LhR/Ib/rbfewqJFizB06FBMmDBBnJajGnHRZZTh1Vdfxbp16/D2229j3759aN26NRQKBa5evYp169aJ++jMmDEDBw8eRO/eveHn54fk5GT89NNPqF69upjAoVu3bvD29kbr1q1RpUoVXLlyBYsWLULv3r1LTW7Qv39/bN68WWNU66OPPsKlS5fw3XffYd++fRg0aBC8vb2RlJSELVu2IDIyEkePHhWfX6NGDbz++uv46KOPIJPJsGzZMnh6eiI+Pr5MvwsVqVSKpUuXomfPnggJCcHo0aNRrVo1JCYmYt++fXBychLXgOmjadOm2L17N+bNmwcfHx8EBARoXQ9W2J49e5Cdna1RPmDAALz55ptYsmQJRo0ahVOnTsHf3x8bNmzAkSNHMH/+fPH3MGbMGDx8+BCdOnVC9erVERcXh4ULF6JRo0biGpt69eqhQ4cOaNq0Kdzc3BAVFYUNGzZg3Lhx4jP1TZH91VdfAchfFwjkpwk/fPgwAOCzzz4T640YMQIHDhxQ+3uhQYMG6Ny5Mxo1agRXV1fcuHEDv/32G+RyOebOnSvWi4yMxIgRI+Du7o7OnTvjzz//VGtDq1atULNmTQD5/Wv79u1o27Ytxo0bB3d3d2zduhXbt2/HmDFjxOQoN27cQJcuXTBkyBAEBwdDKpUiKioKq1atgr+/v5hWXCU5ORnnz5/H2LFjS31PiMiIjJKTjoieG8WlyC4uXfKRI0eEli1bCra2toKPj4/w8ccfCzt37tRImVtcimxtKYIBCF9++aV4XFyK7LFjx2pc6+fnp5Hid8+ePULjxo0FKysrITAwUFi6dKnwwQcfCDY2NsW8CwVUKbJL4+fnV2wK4ps3bwqDBg0SXFxcBBsbG6F58+bC1q1bNerFxMQIvXv3FmxtbQVPT0/hgw8+EDZu3CgAEI4fPy7WK+n3kZubK3z99ddCSEiIYG1tLbi6ugpNmzYVpk+fLqSlpYnvR//+/QUfHx/ByspK8PHxEYYOHSpcv35dvM+SJUuEdu3aCe7u7oK1tbUQGBgofPTRR+I9SnL69GmNtOCFbdiwQejWrZvg5uYmWFhYCFWrVhWGDBki7N+/X63eqVOnhBYtWghWVlZCjRo1hHnz5hWbIlvbe69Kkb1+/Xqt7Thz5owwcOBA8TX6+fkJgwcPFvbs2SPWUfW9ounEtbXj6tWrQrt27cQUzSWlmlb1/+L+rFy5UhAEQbh3754wevRowcPDQ7CyshIaNGggLF++XOv76eXlJb5Xb731lnD37l2xzldffSU0b95ccHFxEWxtbYXg4GBh1qxZQm5urkabdE2RXVL7C1OldC/syy+/FMLCwgRXV1fBwsJC8PHxEV5++WXh/PnzavVU73Nxf4q+FydOnBB69uwpeHt7C5aWlkLt2rWFWbNmCXK5XKxz//594c033xSCg4MFe3t7wcrKSqhVq5YwceJErWnjFy9eLNjZ2YkpyYnINEkEwYS+giUiMlEDBgwoNWWwKZg/fz7ef/993L59G9WqVTN2c3TWuXNn+Pj4YOXKlcZuCtEzady4MTp06IDvv//e2E0hohIwCCIiKiIrK0stQ9iNGzcQEhKCkSNH6rXmprwVbWd2djYaN24MhUKhsc7B1J04cQJt27bFjRs31BbwE5mTHTt2YNCgQYiJiYGXl5exm0NEJWAQRERURNWqVTFq1CjUrFkTcXFxWLx4MXJycnDmzBnUqlXL2M0T9ezZEzVq1ECjRo2QlpaGVatW4dKlS/jzzz8xbNgwYzePiIjIZDExAhFRET169MCaNWuQlJQEa2trhIeHY/bs2SYVAAH5GeKWLl2KP//8EwqFAvXq1cPatWsxZMgQYzeNiIjIpHEkiIiIiIiIKhXuE0RERERERJUKgyAiIiIiIqpUzHpNkFKpxJ07d+Do6KjTxoBERERERPR8EgQBGRkZ8PHxETcXL45ZB0F37tyBr6+vsZtBREREREQmIiEhAdWrVy+xjlkHQY6OjgDyX6iTk5NR2yKXy7Fr1y5069YNlpaWRm0LmQf2GdIX+wzpi32G9MU+Q/oypT6Tnp4OX19fMUYoiVkHQaopcE5OTiYRBNnZ2cHJycnoHYDMA/sM6Yt9hvTFPkP6Yp8hfZlin9FlmQwTIxARERERUaXCIIiIiIiIiCoVBkFERERERFSpmPWaICIiIiJ6figUCsjlcmM3g/Qgl8thYWGB7OxsKBSKcn2WTCaDhYWFQbbGYRBEREREREb3+PFj3L59G4IgGLsppAdBEODt7Y2EhIQK2bfTzs4OVatWhZWV1TPdh0EQERERERmVQqHA7du3YWdnB09Pzwr5ME2GoVQq8fjxYzg4OJS6QemzEAQBubm5uH//PmJjY1GrVq1neh6DICIiIiIyKrlcDkEQ4OnpCVtbW2M3h/SgVCqRm5sLGxubcg2CAMDW1haWlpaIi4sTn1lWTIxARERERCaBI0BUGkMFWgyCiIiIiIioUjFqEJSRkYGJEyfCz88Ptra2aNWqFU6ePGnMJhERERER0XPOqEHQmDFjEBERgZUrV+LChQvo1q0bunTpgsTERGM2i4iIiIjIKPz9/TF//nyd6+/fvx8SiQSpqanl1qbnkdGCoKysLGzcuBHffPMN2rVrh6CgIEybNg1BQUFYvHixsZpFRERERFQqiURS4p9p06aV6b4nT57Em2++qXP9Vq1a4e7du3B2di7T83T1vAVbRssOl5eXB4VCoZHVwdbWFocPH9Z6TU5ODnJycsTj9PR0APkZRYy9sZbq+cZuB5kP9hnSF/sM6Yt9hvRlrD6jyg6nVCqhVCor9NllVXjm0rp16/Dll1/iypUrYpmDg4P4WgRBgEKhgIVF6R+93d3dAUDn98HCwgJeXl4QBKFc91hStafo70j1TNXvr7wplUoIggC5XA6ZTKZ2Tp9+a7QgyNHREeHh4Zg5cybq1q2LKlWqYM2aNTh27BiCgoK0XjNnzhxMnz5do3zXrl2ws7Mr7yaX6O9bUlxJleF0ym408eAmX6S7iIgIYzeBzAz7DOmLfYb0VdF9xsLCAt7e3nj8+DFyc3MhCAKy5cYJhmwspTplqSv82VO1caeq7PDhw+jbty/WrVuHWbNm4fLly9i0aROqVauGqVOnIioqCpmZmahduza++OILdOjQQbxXaGgo3nnnHbzzzjsAAFdXV/zwww/YtWsX9u7di6pVq2LmzJno1auX2rNu3boFZ2dnrF69GlOmTMGyZcvw6aefIjExES1btsSiRYvg7e0NIH8wYurUqVi7di1kMhleffVVJCcnIz09HX/++afW15uZmQkgf02/tgxtCQkJmDx5Mnbs2IHc3Fy0atUKX3/9NQIDAwEA8fHx+Pjjj3H8+HHI5XLUqFED06dPR7du3ZCamoqPPvoI+/btw5MnT+Dj44NJkyZh+PDhGs/Jzc1FVlYWDh48iLy8PK1t1IVR9wlauXIlXnvtNVSrVg0ymQxNmjTB0KFDcerUKa31p0yZgkmTJonH6enp8PX1Rbdu3eDk5FRRzdZq+5qzuHs3GdUCg9GrdYBR20LmQS6XIyIiAl27doWlpaWxm0NmgH2G9MU+Q/oyVp/Jzs5GQkICHBwcYGNjg8zcPDT+2jjB+8VpXWFnpd9HZBsbG0gkEvHzqCoY+uqrr/DNN9+gZs2acHV1RUJCAvr27Yu5c+fC2toaK1euxNChQ3HlyhXUqFEDQH4KaBsbG7XPtt9++y3mzp2LefPmYdGiRXjrrbcQGxsLNzc38VmOjo5wcnKCjY0NsrKysHjxYqxcuRJSqRQjRozAjBkzsGrVKgDA7NmzsWHDBixbtgx169bFggULsG3bNnTo0KHYz9RFn6MiCAIyMjIwfvx4REdH4++//4aTkxMmT56Ml19+GRcvXoSlpSWmTJkChUKBAwcOwN7eHpcvX4aTkxOcnJwwdepUREdHY9u2bfDw8EB0dDSysrK0tiU7Oxu2trZo166dxowy1SwxXRg1CAoMDMSBAwfw5MkTpKeno2rVqhgyZAhq1qyptb61tTWsra01yi0tLY3+l7uFLD8ilkilRm8LmRdT6L9kXthnSF/sM6Sviu4zCoUCEokEUqlU/GMsZXm+qn7R/86YMQPdu3cX63l4eKBx48bi8VdffYUtW7Zg69atGDdunFiuei9URo0aJY6KzJkzBwsXLkRUVBR69Oih9kzVH7lcjiVLloijMOPGjcOMGTPEuosWLcKUKVPw4osvAgB+/PFHbN++XeO5xb3GwnWUSiVu3ryJf//9F0eOHEGrVq0AAKtXr4avry/++ecfvPTSS0hISMCLL76Ihg0bAoDazK+EhAQ0btwYzZs3B4BiYwHV8yUSidY+qk+fNWoQpGJvbw97e3s8evQIO3fuxDfffGPsJulN+nTYVKnkVDgiIiKiZ2FrKcPlGd1Lr1hOzzaUsLAwtePHjx9j2rRp+O+//3D37l3k5eUhKysL8fHxJd4nNDRU/Nne3h5OTk5ITk4utr6dnZ0YAAFA1apVxfppaWm4d++eGHAAgEwmQ9OmTcu8pufatWuwsLBAixYtxDJ3d3fUqVNHXCc1fvx4vPPOO9i1axe6dOmCF198UXxd77zzDl588UWcPn0a3bp1w4ABA8RgqrwYNUX2zp07sWPHDsTGxiIiIgIdO3ZEcHAwRo8ebcxmlcnTgSAoynFBGhEREVFlIJFIYGdlYZQ/uqwH0pW9vb3a8YcffojNmzdj9uzZOHToEM6ePYsGDRogNze3xPsUHeGQSCQlBiza6pdn0gRdjBkzBjExMXj11Vdx4cIFhIWFYeHChQCAnj17Ii4uDu+//z7u3LmDzp0748MPPyzX9hg1CEpLS8PYsWMRHByMESNGoE2bNti5c6dZDtlLpaqRICM3hIiIiIhM0pEjRzBq1Ci88MILaNCgAby9vXHr1q0KbYOzszOqVKmCkydPimUKhQKnT58u8z3r1KmDvLw8nDhxQix78OABrl27hnr16ollvr6+ePvtt7Fp0yZ88MEH+PXXX8Vznp6eGDlyJFatWoX58+fjl19+KXN7dGHU6XCDBw/G4MGDjdkEg5GppsNxJIiIiIiItKhVqxY2bdqEvn37QiKR4PPPPzdKSvD33nsPc+bMQVBQEIKDg7Fw4UI8evRIp1GwCxcuwNHRUTwWBAGBgYHo168f3njjDSxZsgSOjo6YPHkyqlWrhv79+wMAJk6ciJ49e6J27dp49OgR9u3bh7p16wIAvvjiCzRt2hQhISHIycnB1q1bxXPlxSTWBD0PVJ1GwTVBRERERKTFvHnz8Nprr6FVq1bw8PDAJ598oldGM0P55JNPkJSUhBEjRkAmk+HNN99E9+7dNfbd0aZdu3ZqxzKZDCkpKVi2bBnef/999OnTB7m5uWjXrh22bdsmzvBSKBQYO3Ysbt++DScnJ/To0QPff/89gPwU41OmTMGtW7dga2uLtm3bYu3atYZ/4YVIBGNPEHwG6enpcHZ2RlpamtFTZH+66RxWR97Gex1r4oPu5Ru50vNBLpdj27Zt6NWrl1lOAaWKxz5D+mKfIX0Zq89kZ2cjNjYWAQEBGmmPqfwplUrUrVsXgwcPxsyZM/W+Nj09HU5OThWS1a+kvqJPbMCRIAORiSNBRm4IEREREVEJ4uLisGvXLrRv3x45OTlYtGgRYmNjMWzYMGM3rcIYNTHC80RMjGC+A2tEREREVAlIpVKsWLECzZo1Q+vWrXHhwgXs3r273NfhmBKOBBkIEyMQERERkTnw9fXFkSNHjN0Mo+JIkIGokmkwMQIRERERkWljEGQgMnE6nJEbQkRERGSmzDhfF1UQQ/URBkEGIuV0OCIiIqIyUaVmzs3NNXJLyNRlZmYCwDNnL+SaIANRTYdjDERERESkHwsLC9jZ2eH+/fuwtLSskFTLZBhKpRK5ubnIzs4u19+bIAjIzMxEcnIyXFxcdNrTqCQMggxEgvwoiMO4RERERPqRSCSoWrUqYmNjERcXZ+zmkB4EQUBWVhZsbW0hUY0KlCMXFxd4e3s/830YBBmIOBJk3GYQERERmSUrKyvUqlWLU+LMjFwux8GDB9GuXbty32DX0tLymUeAVBgEGYgq7uVAEBEREVHZSKVS2NjYGLsZpAeZTIa8vDzY2NiUexBkSJxwaSAFI0GMgoiIiIiITBmDIAMpWBNk5IYQEREREVGJGAQZCNcEERERERGZBwZBBqLKhsHscEREREREpo1BkIEwMQIRERERkXlgEGQgnA5HRERERGQeGAQZCEeCiIiIiIjMA4MgAxHXBHEsiIiIiIjIpDEIMhBxOhxjICIiIiIik8YgyEAKgiBGQUREREREpoxBkIFws1QiIiIiIvPAIMhAmB2OiIiIiMg8MAgyEGaHIyIiIiIyDwyCDITZ4YiIiIiIzAODIANhdjgiIiIiIvPAIMhAOB2OiIiIiMg8MAgyEE6HIyIiIiIyDwyCDIQjQURERERE5oFBkIEwRTYRERERkXlgEGQgBSNBDIOIiIiIiEwZgyADKVgTREREREREpoxBkIEwRTYRERERkXkwahCkUCjw+eefIyAgALa2tggMDMTMmTPNckqZ5OmEOHNsOxERERFRZWJhzId//fXXWLx4MX7//XeEhIQgKioKo0ePhrOzM8aPH2/MpumNiRGIiIiIiMyDUYOgo0ePon///ujduzcAwN/fH2vWrEFkZKTW+jk5OcjJyRGP09PTAQByuRxyubz8G1wCpUKR/1+l0uhtIfOg6ifsL6Qr9hnSF/sM6Yt9hvRlSn1GnzYYNQhq1aoVfvnlF1y/fh21a9fGuXPncPjwYcybN09r/Tlz5mD69Oka5bt27YKdnV15N7dEl+9JAMiQfP8+tm3bZtS2kHmJiIgwdhPIzLDPkL7YZ0hf7DOkL1PoM5mZmTrXlQhGXMSiVCrx6aef4ptvvoFMJoNCocCsWbMwZcoUrfW1jQT5+voiJSUFTk5OFdVsrdZGxuPzf6+ifS13LB3R1KhtIfMgl8sRERGBrl27wtLS0tjNITPAPkP6Yp8hfbHPkL5Mqc+kp6fDw8MDaWlppcYGRh0JWrduHf7880+sXr0aISEhOHv2LCZOnAgfHx+MHDlSo761tTWsra01yi0tLY3+pltYyPJ/kEiM3hYyL6bQf8m8sM+QvthnSF/sM6QvU+gz+jzfqEHQRx99hMmTJ+Pll18GADRo0ABxcXGYM2eO1iDIlKk2S2VmBCIiIiIi02bUFNmZmZmQStWbIJPJoFQqjdSisivIDscoiIiIiIjIlBl1JKhv376YNWsWatSogZCQEJw5cwbz5s3Da6+9ZsxmlUnBPkFGbggREREREZXIqEHQwoUL8fnnn+Pdd99FcnIyfHx88NZbb+GLL74wZrPKhPsEERERERGZB6MGQY6Ojpg/fz7mz59vzGYYhKT0KkREREREZAKMuiboecTpcEREREREpo1BkKE8nQ/HxAhERERERKaNQZCBMEU2EREREZF5YBBkIEyMQERERERkHhgEGYhqJEjgoiAiIiIiIpPGIMhAJBLmhyMiIiIiMgcMggyM40BERERERKaNQZCBFEyHM2oziIiIiIioFAyCDISJEYiIiIiIzAODIANjYgQiIiIiItPGIMhAmBiBiIiIiMg8MAgyEIZARERERETmgUGQgXE2HBERERGRaWMQZCBMjEBEREREZB4YBBmI5OmEOCZGICIiIiIybQyCDIQjQURERERE5oFBkIFws1QiIiIiIvPAIMhQxJEgRkFERERERKaMQZCBcJ8gIiIiIiLzwCDI0DgQRERERERk0hgEGYi4JsiorSAiIiIiotIwCDIQMTscoyAiIiIiIpPGIMhACkaCGAUREREREZkyBkEGokqMwJEgIiIiIiLTxiDIQJgbjoiIiIjIPDAIMjCOBBERERERmTYGQYYibpZKRERERESmjEGQgUjA9HBEREREROaAQZCBSDgSRERERERkFhgEGYiYIptREBERERGRSWMQZCAFI0GMgoiIiIiITBmDICIiIiIiqlQYBBmIKjECp8MREREREZk2owZB/v7+kEgkGn/Gjh1rzGaVCRMjEBERERGZBwtjPvzkyZNQKBTi8cWLF9G1a1e89NJLRmzVs+FIEBERERGRaTNqEOTp6al2PHfuXAQGBqJ9+/ZGalHZqUaCOBZERERERGTajBoEFZabm4tVq1Zh0qRJkBREFGpycnKQk5MjHqenpwMA5HI55HJ5hbSzWEolACBPKRi/LWQWVP2E/YV0xT5D+mKfIX2xz5C+TKnP6NMGiSCYxgSudevWYdiwYYiPj4ePj4/WOtOmTcP06dM1ylevXg07O7vybmKJ4jKAeRct4GYt4MsmitIvICIiIiIig8nMzMSwYcOQlpYGJyenEuuaTBDUvXt3WFlZ4d9//y22jraRIF9fX6SkpJT6QsvbufiHGPRrFKo4WuPwx+Y3nY8qnlwuR0REBLp27QpLS0tjN4fMAPsM6Yt9hvTFPkP6MqU+k56eDg8PD52CIJOYDhcXF4fdu3dj06ZNJdaztraGtbW1RrmlpaXR33Qbq/znKwTB6G0h82IK/ZfMC/sM6Yt9hvTFPkP6MoU+o8/zTWKfoOXLl8PLywu9e/c2dlPKTCbNX8eUpzCJgTUiIiIiIiqG0YMgpVKJ5cuXY+TIkbCwMImBqTKxlOW/lXlKBkFERERERKbM6EHQ7t27ER8fj9dee83YTXkm4kjQ0yxxRERERERkmow+9NKtWzeYSG6GZ2Ih43Q4IiIiIiJzYPSRoOeF9OneRsrnIKAjIiIiInqeMQgyENX2rgyBiIiIiIhMG4MgA3k6EAQOBBERERERmTYGQQYiKb0KERERERGZAAZBBiKRFIRBz0OiByIiIiKi5xWDIAMpFAOBWwUREREREZkuBkEGIgFHgoiIiIiIzAGDIAMpPBLEEIiIiIiIyHQxCDKQwokROBBERERERGS6GAQZiFpiBI4FERERERGZLAZBBqI2HY4xEBERERGRyWIQZCCcDkdEREREZB4YBBmIemIERkFERERERKaKQZCBqKfINmJDiIiIiIioRAyCDETKFNlERERERGaBQZChFJoPp+RQEBERERGRyWIQZCBMjEBEREREZB4YBBmIRC0KMloziIiIiIioFAyCDEQ9BmIURERERERkqhgEGYhUwuxwRERERETmgEGQgRSeDsfECEREREREpotBkIFICo8EGbEdRERERERUMgZB5YADQUREREREpotBkAFJno4BMTECEREREZHpYhBUHhgDERERERGZLAZBBqRaFsQYiIiIiIjIdDEIMiBVagRmhyMiIiIiMl0MgsoBYyAiIiIiItPFIMiAVCNBjIGIiIiIiEwXgyADEoMgDgUREREREZksBkGGpEqMwBiIiIiIiMhkMQgyIEnpVYiIiIiIyMgYBJUDjgQREREREZkuowdBiYmJeOWVV+Du7g5bW1s0aNAAUVFRxm5WmRQkRmAURERERERkqiyM+fBHjx6hdevW6NixI7Zv3w5PT0/cuHEDrq6uxmxW2XE+HBERERGRyTNqEPT111/D19cXy5cvF8sCAgKM2CLD4HQ4IiIiIiLTZdQg6J9//kH37t3x0ksv4cCBA6hWrRreffddvPHGG1rr5+TkICcnRzxOT08HAMjlcsjl8gppc3Hkcrk4ECTPM357yPSp+gj7CumKfYb0xT5D+mKfIX2ZUp/Rpw0SwYib2tjY2AAAJk2ahJdeegknT57EhAkT8PPPP2PkyJEa9adNm4bp06drlK9evRp2dnbl3t7STI6UIUshwdRGefCyNXZriIiIiIgqj8zMTAwbNgxpaWlwcnIqsa5RgyArKyuEhYXh6NGjYtn48eNx8uRJHDt2TKO+tpEgX19fpKSklPpCy5tcLkfTWXuRpZBg14TWCPCwN2p7yPTJ5XJERESga9eusLS0NHZzyAywz5C+2GdIX+wzpC9T6jPp6enw8PDQKQgy6nS4qlWrol69empldevWxcaNG7XWt7a2hrW1tUa5paWl0d90AMhS5E+Ik8osTKI9ZB5Mpf+S+WCfIX2xz5C+2GdIX6bQZ/R5vlFTZLdu3RrXrl1TK7t+/Tr8/PyM1CLD+OfcHWM3gYiIiIiIimHUIOj999/H8ePHMXv2bERHR2P16tX45ZdfMHbsWGM265ldvpNu7CYQEREREVExjBoENWvWDJs3b8aaNWtQv359zJw5E/Pnz8fw4cON2axnpmSObCIiIiIik2XUNUEA0KdPH/Tp08fYzTAoBkFERERERKbLqCNBzyslYyAiIiIiIpPFIKgcGDHrOBERERERlYJBUDngdDgiIiIiItPFIKgcKJXGbgERERERERWHQVA54EgQEREREZHpYhBUDhgEERERERGZLgZB5UDB9HBERERERCaLQVA5YAxERERERGS6GASVA6bIJiIiIiIyXQyCykHLQHdjN4GIiIiIiIrBIMiAQlzzc2P7ONsauSVERERERFQcBkEGZP303WRiBCIiIiIi08UgyIAkkvz/MkU2EREREZHpYhBkQNKnQRBHgoiIiIiITBeDIANSvZkKjgQREREREZksBkEGJE6H40gQEREREZHJYhBkQOJIkNKozSAiIiIiohIwCDIg1UgQp8MREREREZkuBkEGJOV0OCIiIiIik8cgyIBUbyZTZBMRERERmS4GQQbE6XBERERERKaPQZABcTocEREREZHpYxBkQE9jIGaHIyIiIiIyYQyCDEgcCeJ0OCIiIiIik8UgyIAK9gliEEREREREZKrKFAQlJCTg9u3b4nFkZCQmTpyIX375xWANM0cSSX7ww8QIRERERESmq0xB0LBhw7Bv3z4AQFJSErp27YrIyEhMnToVM2bMMGgDzQkTIxARERERmb4yBUEXL15E8+bNAQDr1q1D/fr1cfToUfz5559YsWKFIdtnVlRB0NqTCdh79Z5xG0NERERERFqVKQiSy+WwtrYGAOzevRv9+vUDAAQHB+Pu3buGa52ZKfxmvrYiymjtICIiIiKi4pUpCAoJCcHPP/+MQ4cOISIiAj169AAA3LlzB+7u7gZtoDlRbZZKRERERESmq0xB0Ndff40lS5agQ4cOGDp0KBo2bAgA+Oeff8RpcpURYyAiIiIiItNnUZaLOnTogJSUFKSnp8PV1VUsf/PNN2FnZ2ewxpkbKaMgIiIiIiKTV6aRoKysLOTk5IgBUFxcHObPn49r167By8vLoA00JwyCiIiIiIhMX5mCoP79++OPP/4AAKSmpqJFixb47rvvMGDAACxevFjn+0ybNg0SiUTtT3BwcFmaZBIYAxERERERmb4yBUGnT59G27ZtAQAbNmxAlSpVEBcXhz/++AMLFizQ614hISG4e/eu+Ofw4cNlaZJJ4EgQEREREZHpK9OaoMzMTDg6OgIAdu3ahYEDB0IqlaJly5aIi4vTrwEWFvD29i5LM0wOgyAiIiIiItNXpiAoKCgIW7ZswQsvvICdO3fi/fffBwAkJyfDyclJr3vduHEDPj4+sLGxQXh4OObMmYMaNWporZuTk4OcnBzxOD09HUD+vkVyubwsL8VgtD3f2G0i06bqH+wnpCv2GdIX+wzpi32G9GVKfUafNkgEQRD0fcCGDRswbNgwKBQKdOrUCREREQCAOXPm4ODBg9i+fbtO99m+fTseP36MOnXq4O7du5g+fToSExNx8eJFcaSpsGnTpmH69Oka5atXrzaJrHRLr0px4VHBDMMfwvOM2BoiIiIiosojMzMTw4YNQ1paWqkDM2UKggAgKSkJd+/eRcOGDSGV5n/wj4yMhJOTU5mTG6SmpsLPzw/z5s3D66+/rnFe20iQr68vUlJS9B6BMjS5XI7e3+9FbEbBnLiDH7ZDVWcbI7aKTJlcLkdERAS6du0KS0tLYzeHzAD7DOmLfYb0xT5D+jKlPpOeng4PDw+dgqAyTYcDAG9vb3h7e+P27dsAgOrVqz/zRqkuLi6oXbs2oqOjtZ63traGtbW1RrmlpaXR33QACPNQIjZDJh5/tPEi/nor3IgtInNgKv2XzAf7DOmLfYb0xT5D+jKFPqPP88uUHU6pVGLGjBlwdnaGn58f/Pz84OLigpkzZ0KpVJbllgCAx48f4+bNm6hatWqZ72FMjd3VB9ViU54YqSVERERERFScMo0ETZ06Fb/99hvmzp2L1q1bAwAOHz6MadOmITs7G7NmzdLpPh9++CH69u0LPz8/3LlzB19++SVkMhmGDh1almYZnYzZ4YiIiIiITF6ZgqDff/8dS5cuRb9+/cSy0NBQVKtWDe+++67OQdDt27cxdOhQPHjwAJ6enmjTpg2OHz8OT0/PsjTL6IqmyE7OyEFOngLWFjLtFxARERERUYUrUxD08OFDrckPgoOD8fDhQ53vs3bt2rI83mTJtEwunBdxHVN61q34xhARERERkVZlWhPUsGFDLFq0SKN80aJFCA0NfeZGmSttb+bfZ+5UeDuIiIiIiKh4ZRoJ+uabb9C7d2/s3r0b4eH52c+OHTuGhIQEbNu2zaANNCcSLWuC8p4hUQQRERERERlemUaC2rdvj+vXr+OFF15AamoqUlNTMXDgQFy6dAkrV640dBvNWsrjXGM3gYiIiIiICinzPkE+Pj4aCRDOnTuH3377Db/88sszN+x5cvP+YwR6Ohi7GUREREREhDKOBJF+Np9ORLZcYexmEBERERERGARViEX7ojFu9WljN4OIiIiIiMAgqMLsvpJs7CYQERERERH0XBM0cODAEs+npqY+S1uIiIiIiIjKnV5BkLOzc6nnR4wY8UwNep79ejAG/Rv5wMvJxthNISIiIiKqtPQKgpYvX15e7XhuuNpZ4lGmXOu5WduuYNa2K7g5uxdkUi2bChERERERUbnjmiADq1fVqdQ68Q8zK6AlRERERESkDYMgA9NlgGfwkmM4l5AKAEjPlmPBnhuITXlSvg0jIiIiIiIADIIMTiopPQq6n5GD/j8eAQBM/+cy5kVcR/fvD5Z304iIiIiICAyCDE6HGEi09FAMTt56CADIVSjLqUVERERERFQYgyAD0ycI+uq/K+XXECIiIiIi0opBkIHpMh2OiIiIiIiMh0GQgekbBAkQyqklRERERESkDYMgA/NytDZ2E4iIiIiIqAQMggxsYucgdA+pgiWvNtWpfsLDrHJuERERERERFWZh7AY8b1zsLLHk1bAyXfvh+nOIf5CJNW+2hEyXDYeIiIiIiEhvDIJMyIZTtwEAp+MfoZm/m5FbQ0RERET0fOJ0OBP0fcR1XExMM3YziIiIiIieSwyCTNDRmw/QZ+FhYzeDiIiIiOi5xCCIiIiIiIgqFQZBRERERERUqTAIMmHZcoWxm0BERERE9NxhEGTCOv1vPxRKwdjNICIiIiJ6rjAIMmF30rIR+Ok2LD0Ug+MxD9TObT5zG+PXnEFOHkeLiIiIiIj0wSCoHO2e1N4g9/nqvyt4+ZfjSM+Wi2Xv/3UO/5y7gy//vmSQZxARERERVRYMgspRkJeDQe8XOm0XHj7JVStbezIB2XIF9l1LxqMi5wRBQGTsQ6RmqpcTEREREVVmDILKWYCHvUHvd6LItDgACP58B0YvP4m+iwr2FsrJU+DPE/EYvOQYOn93wKBtICIiIiIyZxbGbsDzbuM7rRAZ+wBvrzptkPv9fDAGXk42Ws/dfpQl/tx13kHEP8wEADx4wpEgIiIiIiIVjgSVMzd7K/SoXxWBnvkjQp2CvZ7pfucSUvHi4qOl1lMFQKW5cDsNV5PSn6lNRERERETmxGSCoLlz50IikWDixInGbkq52PROa6x6vQV+HRFWrs/JyJZj4Z4bOtVNy5Kj76LD6DH/EFNxExEREVGlYRJB0MmTJ7FkyRKEhoYauynlxtnOEm1qeUAmlcBSJim358z67wq+i7iuU91/ziaKPysF3YOgtCw51kUlIC1LXnplIiIiIiITY/Qg6PHjxxg+fDh+/fVXuLq6Grs5FWLjO63K7d4nbz3Uue7nZUyv/d6aM/h4w3lMWHumTNcTERERERmT0RMjjB07Fr1790aXLl3w1VdflVg3JycHOTk54nF6ev5aFrlcDrncuKMSqufr0o5gLzu0CXLH4WjNTG/l5ftdV9GrvjdqemrPVnfi5n3U93GCvXXpXeLg9fsAgP3X7hv9fTdn+vQZIoB9hvTHPkP6Yp8hfZlSn9GnDRJB0GMelIGtXbsWs2bNwsmTJ2FjY4MOHTqgUaNGmD9/vtb606ZNw/Tp0zXKV69eDTs7u3JureFNOGb4GLSKrYB7Wdqn20kgYH64otjnV7MT8HFDRdHLNBS+7ofwvDK2lIiIiIjIcDIzMzFs2DCkpaXBycmpxLpGC4ISEhIQFhaGiIgIcS1QaUGQtpEgX19fpKSklPpCy5tcLkdERAS6du0KS0tLna4ZujQSUXGp5duwIm7M7Cb+XOvzXSWeL07h63SpT9qVpc9Q5cY+Q/pinyF9sc+Qvkypz6Snp8PDw0OnIMho0+FOnTqF5ORkNGnSRCxTKBQ4ePAgFi1ahJycHMhkMrVrrK2tYW1trXEvS0tLo7/pKvq0xcVO87WUN0tLS6w4EgtFMaGvvu+jhYUFJBL1kac8hRIWMqMvNzMbptR/yTywz5C+2GdIX+wzpC9T6DP6PN9oQVDnzp1x4cIFtbLRo0cjODgYn3zyiUYARIax7HAsZmy9XObri6bSfvmX4/jrrXDxeMa/l7E6Mg67JrZHDfeSpyjuvnwPVhZStKvtWeb2EBERERHpy2hBkKOjI+rXr69WZm9vD3d3d43yykAiASpiYmJpAZAgCLiTlg0fZxuNER5BENB7wSG1shOx6tnolh2JBQD8uC8aXw8qPuX5wye5GPNHFADg5uxekEnLL204EREREVFhnLNkInycbY3dBABAwJRtaD13L34+EKNWfivlCcK+2o2rSRka15yOf4SPN5xDyuOC9VoCSo7oCu8xxI1aiYiIiKgiGT1FdmH79+83dhOMRmJiAyFf77iKdzoEisczt17Ggye5WusO/OkoACAjuyBTXGmjWtpebmZuHs4mpKK5vxvXFBERERFRueEnTSN6vU0AAKBLXS+TC4KKytNhtCbm/hONsk82nIf/5P+w9fydYq9TjRq98UcUhv16Agv3Rpe9oUREREREpWAQZEThge44ObULfnk1zNhN0ertlafgP/k/HLpxX+81O+tP3ca0fy7hr6gEAMC41WfUzmsL+o483Tx2dWR8ifcWBAEXbqfhSU4e5my/gvVPn0FEREREpAuTmg5XGXk65qfJlmidIGZcOy4lAQBe/S0Srnalpxy8dk99vdCKo7fUjsf8HoXJPYMR5OWgVl506lxp8da2C0kYu/q0WtlLYb5a6wqCoJHggYiIiIgqN44EmQhTT472KFNeeqVS7L5yD6NXRCLi8j189d8VsbxwQgWg9IBw85lEnZ638ngcms/eg2takjkY254r93AxMd3YzSAiIiKqlBgEUYVKeJiFN/6IQsTle2JZm6/3YU2hKXClDdzoMrAjCAI+33IR9zNy8PGGc2VtbrmITs7A679H4YWfjxu7KURERESVEoMgE1F4ytYvrzY1YkuMY8qmgo1zi8Y4aVly+E/+D/6T/8Oxmw90ul/K44JMdudup2HC2jMl1K5Yt1Iyjd0EIiIiokqNQZAJauTrgpn9Q4zdDKO5k5aNjzecw/92XkO9L3ag4fRd4rmhvx7XafVU0X2K/j5bfHa6it6niEuUiIiIiIyLiRFMhKejNWJT8lNMuztY49Vwfyw/cgsxKZpppyuDdVG3iz1XWhDx6eYLkOcpdXrO/YwcdP5uP3qHVsWcgaH6NJGIiIiIzBRHgkzE3IEN4Otmi1kv1BfTUf/0ShMjt8q8RMY+xKebL2D1iXisP1V8EFXYyuNxSM/Ow5pIptkmIiIiqiw4EmQiano64NDHndTKgr2djNQa03YuIU2jTBAEDF5yTKfrT8U9xNmENAxqWh0L9txQO5eamQtnW8tyTavN6XBERERExsUgiMxOUnq2Rtnp+Ec6X//i4vxg6ad90WrlOy4m4e1Vp/Ba6wB80bfeszWSiIiIiEwWp8OZkdVjWhi7CSbrp3039b7mwZNctePZ2/L3Llp2JFan62NTnuDvs4kQiu72WgpT3BiXiIiIqDLhSJCZsLOSoVWQh7GbYbL2XE1+5ntom6b2+9FbsJRJMaxFDdxJzcLMrZfRKtAd1V3tMHrFSQCATCpBn1CfZ34+EREREVUMBkFmxsnGAunZeRrlXetVgbOtJTbomBCgMrqXno3HOZrvnUrcA/X9e1Ie5+DLfy4BAAY2qYZWc/cCALZfTFKrdzoutUKCoDyFEhYyDt4SERERPSt+ojJx3UOqAABebxMAAPj3vTYadSykEvw6Igxhfq4V2jZz02L2HnT+7oBOdY9EpyArVyEeX03KKLbu1aR0teN76dk4Ep2iVnYxMQ0Np+/Cgev31XaDzVFAJ4du3Eetz7Zj5fE43S6oQPfSs5Et1/GFEBEREZkABkEmbsHQxtj4TjgmdqkNAPBzt8e28W1x4tPOYp2fX2mqcd3pz7vi1ZZ+FdbO583wpScwdvVp8XjAj0eKrXv05gO14xaz92D40hP5Ac9TfRYeRlqWHCOXRarV/TjSAn8WSs+99FAMFu1Vz1gHAGP/PA1BAD7fclHv11KeEh5mosXsPWjz9T5jN4WIiIhIZwyCTJy1hQxN/dzEvYMAoJ6PE6o42YjHno7WANTXtLjZW4nlVDbnb2um4i7O4CXHMGTJMfx9NlEsG7ksEve0ZLIruvRo2r/5CRly85T46r8r+N+u60jWcp0p2v800Et5nGPklhARERHpjkHQc8DRRvvSrgAP+2Kv2TK2dXk1p1KKjH2IE7EPMWHtWbXy138/qVFX2x5Ee6/eQ6u5e8TjrCLTy8pz36JnYZqtIiIiIioZgyAzNqN/CCZ2qYWang4AgKKZmns3qFrstY18XfBJj+DybB4BuJiYrlGmLXnFayuikPK4IGW3Qimgx/yDaDxjF07EPECeQime++Lvi0jLkuvVjvm7r2NVOawnMtHYjIiIiKhEzA5nxkaE+5d4XiqV4PpXPXEs5gHWRsaLWc0+610XAGBtURAD//JqU7y58lS5tbUy+3jDObXjf8/dKfWaE7EPxWQMQ345rnbuj2NxkCsEfDWgPgRBUMsYJwgCchVKWFvIxLLo5MeYvzt/nVGgpwOa+bsyyxwRERFVavwk9BzR9q28lYUU7Wt74sdhTcSywuuLVLqFeJdn0yq1dVH6py2fF3G9xPM37z9Gx//tR5uv90GhLBgCHLn8JEK+2IkHhdboFE4LPvTX41iwN1rtXjl5Cvx9NhEnYh5o3fh1XVQC5u8uuT1ERERE5oRB0HPE19Wu2HPSQoGP6nNuoxouanXWvx1eHs2iMrifUXKigcfZeYh/mImk9GwkZ2RDEARM2XQeB6/fR55SQNOvdmP35XsANNftrDx2S/xZoRRQ57MdmLD2LIb8chxtvt6HV5aeUEvw8PGG85i/+wYuJuYninj4JBdrI+PxOCcPEq4KIiIiIjPE6XDPkfBAd3zZtx7qVHHUer59bU8cuH4ffRvmb+zZpIYrVr7eHDXc8oOnZv5uFdZWejaFx2ukEgn2X7uPNYVSbQPAmD+icGtub40RwkIDR7iblqV2LjE1C4mpWTgcnYL+jaqpnUvPzl+HNHrFSZxLSMWRmw/QKtD9mV8LERERUUXjSNBzRCKRYHTrALQK8tB6fsXoZrg6s4da6uy2tTzh516QRW73pPZq19TyckDv0OITLJBxXLlbkHDhwu00jF6hmYUOAPovOozYlCdqZYIgQBAE3EvPLjHrXOFkDIWdS0gFAPx3/o7aONCWM4la6xMRERGZGgZBlYhEIoGNpazEOkFeDlg8vAlqV3HAP+NaY9f77fDdSw211n2xSXWNsqUjwgzSVtLdmD+iij137naaRtpuAcBHG86jxew92H7hbrHXDlx8FBnZcvULCykaQE386yySM9T3N9pz5Z5GEAbkr0PKLpIG3FTtv5aM6OQMYzeDiIiIDIhBEGno2aAqdr3fHqHVXcTA6dbc3oj8tDMa+bqI9Wb0D8Gb7WqqXSuTaR9Z6MHECyZDEArSdP+w50ax9c7fTsOiIkkUiio6kJReKHX38ZgHeP33KHT83361OkqlgLCvdqPRjF3FjjaZiouJaRi1/CS6zDto7KYQERGRATEIIp15OdmgpmfB1Dl7awt82quuWh1Ph4Kpdic+7Sz+/M1LoeXfQNJJ4WxxGdl5JdQE4h5kij8LAKZsuiAeK5QCHjzJVat/JPqBOMKjmjansu3CXfx2OBYZOXnIyM5DtlyptjeSLpLSsvHzgZt49ES/68rq8l3NfZ6IiIjI/DExAunl8971YG0hxaCmvlrP16/mjM/71IOvqy2qONlg3uCGkEokcLKxrOCWkiHsuJQk/jzrvysaQcE3O66pHX/5zyWcTUjF90Ma4UmhYOvC7TS8++dpAICLrXpfOJeQisxcBcKLSbKw42ISNp2+jW8HNcQrv51AdPJjHI95gBWjm+v0GlIe58DZ1hKW3BuJiIiInmIQRHpxtbfCnIElj+q83iZA/HmglnVDZJ50HRXZfCYR0/qFqO1H9M+5gqQJH6wv2Dx2wI9HkJSev47o1Gdd4GZvpbHW6O1V+Zv4+uy+jujkxwCA/dfu69SW6OQMdJl3EPWqOmHbhLY6XaMPpVJQSz9PRERE5oFfjVKFWTi0sU71mvm7ij8PasogyhydinuodqxlD1YAEAMgAEjOyEH/H4/g3T9PiWWZuQWjSSuO3tK7HX+fvQOgfKa1vbfmDNr/bx+ycs0jwQMREREVYBBEFUa1P1FRYX6uasfVC236GuLjVK5tovIxad05teNiYiA1r604ifO307DtQv4UvLRMOep9sdNgbdpx8a5eAYtCKeC7XdeKPf/vuTtIeJiFPVfvGaJ55SYtSw6lUpffABERUeXBIIieWRWn/GQIDtZlm13pYqe+RuSz3gXJFiQA+nCfIrOTmikvvVIRd9PU02sfjk4xVHMAAG+vOo1PN18oveJTW84k4l56Tqn1ihvlMgXRyRloOH0XXl12wthNISIiMikMguiZ/TmmBXo18MaGd8JLrXvi085YPaYF3OytxLIv+4aIPzvZWMC9UIY5iUSCV1v6GbS9DQul+aaKoW+gIAgCTsc/0qluWqYcn225gKhbD3ExMQ0L9tzAlE0XUHPKf1hYJMX35qcbuiqUAuKfZr6bF3Edvx6M0bjv7UdZ+jXaBK2NTACQn7WPiIiICjAxAj2zIC9H/DS8qU51qzjZoIqTDQ593BH3M3Lg72Gvdr7oongAaB7gVuI9h4T54q+oBJ3bK5jyV/fPqbgHmhumlqTXgsO4Uso6nst30tFrwSHxeNXxeJ3v//aqU4i4fA+TewZjwdO9kl5vE1CmJAem3Ju0/O9EREREMPJI0OLFixEaGgonJyc4OTkhPDwc27dvN2aTqILYW1uoBUAWTz98NqjmrFZPIskPjH5+pQkAwEpLmuOXwrQnT1j9Rgut5UoGQRVuz9VkveqXFgABUAuA9BVxOX8dz4ISNosVdAxvBEHAhlO3celOWpnbU160falARERERg6Cqlevjrlz5+LUqVOIiopCp06d0L9/f1y6dMmYzSIj2DahLUa18se8IQ3VylUf4XrUr4pbc3vj2lc94Ph07VHP+t74bWRYsd92twr00FquVAJb32uDGf1DtJ7Xl2MZ10KRccSmFIxKZRZKlFA4OJYrlDrfb8+VZHy4/hx6LziscS49W47+iw7jl4M3y9jaZ8MQiIiISDujfnrr27ev2vGsWbOwePFiHD9+HCEhmh9Qc3JykJNTsFA5PT3/22K5XA65XP+F2Iaker6x22GuAtxsMLVnbQDq76FCqdR4TyMmtsa1e48RXtMNEokEp+LU147U9XZE/WpOate90NgHDas54fs90Zg9oB7qeNmhqqMlvvj72QPuTe+0QNf5R575PlQxOv5vv9byXLkcglKKGf9dxcrj8WgZoJ61sHB/2n6xYBPZi4lpWusAwNKDN3HudhrO3U7D6PAaAICMbDmy5Up4OlpDX8X9PXM3LRufbrmEUeE10L62p1iuVCo1rqXKhf82kb7YZ0hfptRn9GmDRDCRBRIKhQLr16/HyJEjcebMGdSrV0+jzrRp0zB9+nSN8tWrV8POzk6jnMzXhGP58flLAQq08S65i95MBxZcKojnfwgv2FtGdZ/mnkoMD1JCKQCqZR/ZCuCTyGf/HuCH8Dx8dUaG+9n83t2cfdciDxbSgj5T1PyWeThxXwIbGbD8ukws97IRkPz0d/918zzcywJq2OdP5fw3Tordd/IH3FX9UnX/Oc3yYGcB3EiTYM1NKQbXVCLYpWx/HS++LMXVNPXnAMA/cVLsuaNZTkRE9DzKzMzEsGHDkJaWBienkrdZMfo8ngsXLiA8PBzZ2dlwcHDA5s2btQZAADBlyhRMmjRJPE5PT4evry+6detW6gstb3K5HBEREejatSssLS1Lv4BKNOHYLgBAgwb10auZb4l1o+IeYcGlk+Jxr169NO7TJzxE4z5ZuQp8Ernnmdr549CG6FavCuLsYzBvd3TpF5DJyqkair03HwJI0nr+smUQ1ty8pVFub28PZOdnmlMF1XNeCMGgJtVwedcN7L4TCyC/X+YplMCx3QCANXfc0DrQHYsv559ffEWG6zO6lriOR9vfM+tP3cbVY5fFOoX7/6Vd17Hnzi2Ncqo8+G8T6Yt9hvRlSn1GNUtMF0YPgurUqYOzZ88iLS0NGzZswMiRI3HgwAGtgZC1tTWsrTWnkFhaWhr9TVcxpbY8D2QyWanvp6Otep8oXH/3pHY4EfsQLzerAVmRzF9KSdmXxHWs44mxHYMQ5p+fue7djrUQUs0Fr/8eVeZ7knF9uuVyied/OXRLa7m2sZvNZ+5iaAt/xD0sSLM9a/t1/HWyIIvh+cR0nE9U/8t6VWQiXmsTUGpbC/89U7Tdhfu/TCZTK990+jZquNmJ/ZYqD/7bRPpinyF9mUKf0ef5Rg+CrKysEBQUBABo2rQpTp48iR9++AFLliwxcsvIFEh0WNod4uOEUa38cfP+Y3w7SD2xQpCXI4K8HLVeJyv0jftPw5tgycEYvNKiBjwcrfHf+bvYcOq21uvGd66FiZ1rqaVTtpBJ0bluFV1eEj1nbj3db6gw6dP4eselglGlFUdvlXqvGVsvQ6EU8HJzXzjaPPs/JIX/7zmXkIpJ684BAG7N7f3M9yYiIjJnRg+CilIqlWrJD6hyGtq8Bg5H30f/Rj6l1pVIJJjWT/9Mb4VHhrwcrfH32Nbiccc6XninQyDSsuQY+NNRtesmda1d7D1retgjJkW/PXHo+SN9htTUs7ZdwZWkdMwb3AiPnuTiUWYuano6YNHeG6juYqNXxrfCzbil515NREREzzOjpsieMmUKDh48iFu3buHChQuYMmUK9u/fj+HDhxuzWWQC5gxsgIMfdYR9OaafLrz2QqllTlOgpwOa1HBF1GdddL5nmL96RjF7Kxnc7K3Uyka18ternQDww8uN9L6GjOfC7TSkZuaW+fpNpxORmpmLxjMj0Om7A9hyJhH/23UdE9edL/M9i1trlJ4t13szWyIiInNn1JGg5ORkjBgxAnfv3oWzszNCQ0Oxc+dOdO3a1ZjNIhNRkRs9lrSBqp1VwbqK0oKRwrdZOiIModWdIVcK2H35Hr78Jz8ddz0fJ7Ss6YbjMQ91bl//RtUwYe1ZneuTcWXk5KHTdwee6R6NZkSIP0/866z4887bEoRl5KCaW+nT5XSZTtp0ZgTkCgH7P+ygtoExERHR88yoQdBvv/1mzMcTiUoKggp/kGzk61LifRpUd8b6p2uJutQrWCM0spW/GATpG9pxFMg8PXxS9pGgkmxLkOHAD4cxoFE1vN0+UOO8QilAJpUgOT1bbQpc4X6XnJENL0cbAIBckd/3T8Q+UAuCBEGAUoBGQpHSxNx/jIt30tE3tGqFfpFBRESkD5NbE0RkDEGeDga5z7DmNaBQCggPdC+2TkkfDF3tLPEoU32jr/6NqgEArCykyM3L3/zy9Odd0WRmhMb1hjS5ZzDmbr9ars+gsnmSo8CfJ+Lx54l4jXNNZkZgSDNf/HIwptjrm8/ag6GlJF+YsPYsTsQ+wJ4POsBBj2mpqhEwmUSC3qFVxfLHOXk4EfMAbWp5wNpCVtzlREREFYJBEFVqRyZ3Qka2HF5ONsXWEQolQS5tepGFTIrRrbWnOPZxtsGdtGy0CfLAhlMJWuvs/7Aj4h9mou+iwwCAxjVcxHPbxrfF2sh4vNU+UG2dUedgL1RxtoGPsw2OxTzA6FYBqOZqixvJjzF+zZkS21uSt9rVRHqWHD/tv1nme1DFS8uSlxgAqayJ1N4HVf45dwcAsPNiEl5sWl3vdpyJf4TeoVUhCAJSM+UYt+Y0jkQ/wGutA/BFX+17wREREVUUBkFUqVVzsQVgW2IdK1lB/hBX+7KnLd73UQc8yVHAzd4K7Wt74XjMQ1hLBeQoCwIrZztLNLBz1np9kJcDPuuj+eHRykKK2S80AACM61RLLPdwKNg/adv4tui14FCJ7etS1wu7rySLxxKJBB/3CMbELrVx9GYKRi0/WcLVZOqO3nxQ4vnE1Gx8vOEcHmXK8f2QRmL5kegU7Ll6D+721pg5oL7GdeuiEmBtIYWXo43WEdD3/zqLLWfviMd/nYxnEEREREbHIIioFBYyKbaNb4s8pfKZ9m6xtpCJ04DGtA2Ap70FnsSexZenn+1/w+KWM3k6WuPnV5rAxlKGej5OYnmgpz1u3tfMBrZ0ZDPM+Pcylh2JVSu3spCiVaDHM7WRjG9NpObUucIW7Lkh/vze6tPiz5vOJIo/t63lgU7BXjgV9wgNfV1w5W46Pt5QkLFu7ZstxZ+XHo7FZ33qqQVAKrdSnuCjDecwunUAqjhZI7S6CyxlmslKbz/KxMXENHQP8eb6IiIiMigGQUQ6KBxEGIKlTIr+jXyw7c5ZrecHNa2ODaduY3yhkZ2iutargojL9/BaG+3T7wCgR/2qGmUvN6uBvg194O5ghYSHmRi3+gze7Zi/wH5q77oI9nZE29rqQY9FocXxAR72iC2yF1KwtyOuJmUU2w4yL/uu3dda/ubKU3C2tURaVv66tYGNq6mdj4zVLePhaytOIiblCU7eegQgf1+wOQMbaNRr8/U+AMCCoY3Rr2Hpe4YRERHpyqj7BBER8GHX/EDn80JT3b4dFIrTn3dFx2CvYq9b8kpTnPqsC5oHuOn0nH/HtcFH3etgZCt/eDvbwFImRU1PB2yb0BZ9QvM/YMqkEgxu5ouqzupTBKWFgqD/vRSqkbFubMcgtePQ6s7YPqGtTu0i86IKgAD1USJA94x4RTcUXhMZD0EQkC1XaK1/rJSpfERERPpiEERkZG+1C8Cpz7rg9UIjOhKJRGOT1aKkUgncC637KU2D6s4Y2zEIVhZl+98+2NsRbvZWqF/NWcxYVxxBAOpWdcJvI8PK9CwAqFPFsczXknGsOHqr1DpPcrUHOh+sO4fgz3fg5v3HGucSHmZCKCGNPRERkb4YBBGZAH2CGWP5b3xbHJ/SWWt6YwHArBc0F83nPE3pXRZfDwpF7wb50/m4HMQ8vbZC92QaqlGl+btvYN+1ZOQpCvrO4egUzN1RkK49KS0bE9aewen4/Ol0OXkK/HY4FtHJBQHUvmvJ+GTDeWRpCboUSvWAShAE3EnN0rmtRERk/hgEEZFOZFJJsaNINhZSDG/hJx6HVs/PcBfm7wogf/8jfUkAfDe4Ib7oUw/7Puig9/VkfHuvJpdeqYh/z93B6OUn8csh9TTfSw4UHE9YewZ/n72DgT8dFc/N3HoZXeYdQL9FhxFx+R5GLz+Jv6ISsPiAeor3xNQshE7biRn/XhbLpmy6gFZz92J9VMlpw3WVmJqFpYdikJEtL7Xu32cT8d/5uwZ5LhER6Y5BEBE9s851qwAAdr3fDuM7BWFyz2AAgJejDaI+64JjUzrrdJ/5hVIzA4CNpQyvtQmAv4c9vh0UatA2k2n7Zse1Ys9duZsu/tx0ZgTmRVwXj8/fTsMbf0SJx1G3HuLynYL6P+6LxpNchZgFcf7u61h7MuHpzwUZ8rLlCmw+cxv3M3I0nv/R+nPo/+MRtdGqwl748Qi++u8Kvvz7UomvMTUzFxPWnsXY1aeRk6d9miAREZUPBkFE9EwWDG0M2dPECbWrOGJStzpqqcQ9HKxhY6k+hU5aZHrbvg874Nbc3hjQuPi1Ri+F+Yr7IVHllldoOtuDUpIxHL35AL0WHBKnuxVdWlQ48Cm87uj7iOt4/69zeHHxUY17rj91G+cSUnEsRnvChuSngdOh6BSt57/aehmL9t5ARnaeWFZ0ih4REZUvBkFE9Ez0XbD+VruaOP6p+shQVWcbjXra1gG93My31PtvfCdc7fjrFxtg96R2Wuv+/ErTUu9Hpqcsa81uiOuFCvrr14XWGamfAXZdvgcAiH+YCSA/SHl9xUmsLbTfkiAAx2MeYOSySMQ90Nx7S9v/GjH3H2Pp4Vj8b9d1tXIJuPCNiKgiMQgiomeiawz0w8uN0DnYC2M7BcHVriDz3Y/DmmiMFBVHKpWgcQ2XEus09StIGb5oWGMMaVYDQV6OOPVZF7Qokk68U7AXPJ4mpRjWooZuLwTAiU91m95HhvXOqlPwn/xfmUZNRi6LxH/n76r118X71dcL3U3LxpjfozQC+zqfbUfgp9uw52oyJm+6IJZLJMDLvxzHgev3MX7tWQD5a3xKklVMGvBsuQK5eUoIgoC0THmx6cKJiMgwuFkqET0TAbp9IO3fqJpaau2L07sDABystf81JC0mJdwXferhhZ+OYmjzGlhT6Ft5AGKa8aUjwnAq/hF6Fdos1t3BGhO71MbQX4+LZVYWUkR91gUA8OtB9YX4LWu64XiM9s0/7a0t8HIzX3EtCVWM7ReTnun6satPl7qv1u4r93D7UZZaUoPiRp4Kj94kpeVPt5vwNBgCgJTHmuuJCsdXhX9uPDMCAGBnJUNmrgKO1ha48PT/ESIiMjwGQUT0TMq6fUtxwc/Q5r5ISstGvapOWs83ruGK61/1hJWFFG+1qwl7aws0m7UbAGDxdLFRl3pV0KVeFY1rW9Ys/gPwq+F+OJPwCNsu5H/Q9nTUnKKnIpNIdB69ItMSGas9sC1s8JJjSHlc+savV5PSS60jVyjxJCcPLnaa+359u0sz+UPm05TeGTl5GueIiMhwOB2OiJ6Jr5udQe83Z2Aolo9uDmnR7AmFqFJ1+3vYw9PRGu93qQ1/dzu81T6wxHtLJBJEvN8OnYK9sPbNlmrnbCxl+Gl4wRqhwlOiFg5tjD6hVQvdB+hR31vn13To44461yXju5uWrVO9r/67UmqdHvMPotGMCNxNy4JCKWDnpYLRrH/P3SlzG4mI6NlwJIiIymTdW+GIuf8YzfxLnl5UESZ0qYUJXWrpVLdWFUcsG9Ws1Hphfq7Y+nT/lj6hVRHs7SgeSyUStKzprnP7tAWKo1r5Y8XRWzrfg0zbvfQccUSysJv38xMmTFh7VqdRqOKcvPUQV5MykJyejXc6BMLOSrd/vjNz85DD5UVERBoYBBFRmTQPcCt1fYU5OjalE+IfZMLWqmC6m0QiUVv5VHSQqpqLLRKfpmAuSlbMiNa0fiHIlis01hV1q1dFzExG5kXbnkIqZQmAjt5MgZ+7PZxtLfHSz8fE8kX7ohE7p3ep1yuUAhrO3AvAAn16KWGp/57FRETPLU6HIyIqpKqzLVrUdNdY61T4uGjShmJyODytm/9fVcBoKZMgcqpmdrkjkzvhp+FNmLabRMN+PYHWc/eqbQ4LFPTFdVEJ2HctudjrCyd3eJQpVzsnVyjxx7FbiBZThxMRVS4MgoiIdFB4RKek9UpFSZ5GSD8Nb4IPu9XGoY87wUtL0oVqLrbo1aAqpFIJvh/SEADQrrbnM7aangeFR4FUTsc/wscbzmP08pPI1WHfpKI99peDMfji70voMu+ARqpwbfTdD4yIyNQxCCIi0qKaq63acaCnPQY08sHo1v4adV3sLNXqFaZKqODhYI1xnWrBu9DGsK+09AOgGey80Lg6bs3tjQ+61i5Ut/h9jP54rTkiC+1ddHxKyfsY1fSwL/E8mb6BPx0Vfw6fswcAoHy6f5IgCKUGLd/uLMhM9/WOq1h2OFbtvCAIuH4vA0qlgCmbzqP7/IMVvnfR+dupePik9Cx9RERlwTVBRERaeDhYY+t7bWD3dG2QRCLB/Jcbq9X5bWQYFuyNxrzBDXEnNQvHbj7A+M61sO3CXdSu4ojLd9LRu1BWuaLqV3PGmc+7wtlW+2KNhr4uWDG6Gaq72iHIywGrjsdrrRfgYQ8vJxv8N74NsuUKeDvb4KPuddQ+6BbWtpYHYlKe6PI2kBl48CQXk9adxb/n7qBuVSecv52Gai62WP92uFgnO0+BPIUSFjLt333O2HoZ/Rv5wNnWEhYyKeZFXMfCvdEY1cofayITxDojw/1Rx9tR7drfDsciwMMOnYI109KX1am4R3hx8VFYyiS4MauXwe5LRKTCIIiIqBj1qzmXeL5z3SroXDf/g1+gpwPa1sof0RnYpLpO1wOAq73m/jGFdajjpVE2upUfmgW4Y/vFJFjKJKj+dNQqxKfgeWM7BmFUK3+EfLmz1DaQ+dt0OhEAcP52GgAgMTUL2y7cFc93mncYAHD2i65wtNEedDf9ajfqVnXC9gltsXBvNACoZTBcfSIeq0/E49bc/KQMuy/fw0cbzonrjVTlz2LJgZtIy5LD8mmwJldwGh4RlQ8GQUREZuLNtv7460Qs3mrrD29XB/RqUPwoEwDYW1tg1est8MpvJ57pue72VnhQxmlJTf1ccSru0TM9n8pGW5bBRjMiSrzmyt10RCdn6HT/MX9E6dWezNw82FrKIJFIEHXrIfzc8/f5KmzO9qsAgP6NfPS6NxGRvrgmiIjITHzUrTamN1HA3cG69MpPtanlgb/HtoalTPdkDkUtH90MTjb6f2fWsLozNr7TCiPC/cr8bCq7su5LtGBPdInnV5+Ix+SN5zXKkzOK32Q2OjkD9b7YiQlrz+JIdAoG/XwMLZ+uZVIpvI7pSTGbG0366yzGrzlTYvuIiHTBIIiIyIyUlI67OA19XdTWHTXxcy22boCHPT7pEaxWVruKo5jlDgAOftQR3k428HO3Q+ug4jeNXToyf1PaT3oEY1zHIP0bTkaR8CizxPOfbr6gsb8VADSftUdMzgDkJzaYF3Ed9zNyMGHtWQDAP+fu4L2nQYxCqT7VrXAuh8IBUfrTVN/p2XJsOpOIf87dUQu4iiaBSEzNwpYzichTlJ41j4gqLwZBRESVQJ/Q/OlF9ao6oV9DH8wf0khrvX0fdsA7HQKx4e1wvNikOpa82hQ2ljIsHRkGRxsL/O+lhqjhboeDH3fE3g864M8xLcVrOwV7YdGwguQRqqlO9tYW+LB7nfJ7cWRQZ+JTy3xtzU+3ITdPieT0bPRbdAQL9txAs1m7celOwV5HhTO+HYlOEX+OvFUwclU4rPn9yK38MrUgKf+/41afRsCUbdh85rZ4ruO3+zHxr7NisFVwjYDLd9IhLxQcCYKA6OTHGgEZET3/GAQREVUCk3sGY8HQxvhzTAtIJBIMaFxNPKfKgOdeKElDmL8bvhvcEN1DvAEAzfzdcO6LbhjUND/pg5WFVG3vJADwdLDW2GTWEGpXcRB/7t/IBytGNzP8Q8hghi89jjZf79Oxbv56tWWHY/HyL8fF8r1XCzaBzSlhH6St5/OTP7z/1zlM2ZQ/RS/3aZCz/WISDt/ID7Iu3UlDm6/3odeCQ5i07px4/e9Hb6HLvAP4aMM5EFHlwiCIiKgSsLGUoV9DH63Z6CZ1rY25Axtg6/g2Jd6juE1iP+tdF4Ge9vigW20YOgYa2LgautYrSL38w8uNtWbMI9Nx8tYjMRDRxejlkZix9bJez9AWbKtSeRd24Hp+MNV7wWEkpmYBAP49d0c8P/tpIgZVdj1t0jLlZdosNievYvdVIiL9MDscEVEl17Kmu07pvIszpm1NjGlbEwDgW2ST2eIEezvialJBFrJpfeth2r8FH4QbVHPGhcQ0DAqrjsa+rkjNlKNn/ZKz4RXmZGOB9Ow8neuT8ey7dr/UOmlZugUiayLV99L69VCsmMJbm9wio0wZ2XJYSKWwsZTi0p10pDzOwajlJ9Hc3w0Tu9TCsZgHmNC5VrH7Lal88fdF/HEsDjsnttPYV4mITAODICKiSuro5E64k5r1TAFQUY1ruOKbF0NRw92u2Doudpb4bVQz/LQvGpfupGNkKz+80Lg6tl1MEjOabXgnHElp2fBztwcAzHqhgdo91rzREkN/Pa5xbyB/M9jvXmqI5rP3aD1P5mXRvmgs2qeesW7x/mikaEnbPmXTBY2yDadua5Sdjn+EjzeoZ7j7aX80vtlxDRIJsOSVpnhz5SnxXOSthxj2dOqej4sthjavUWKb/zgWJ7Z94dDGJdY1VUquk6LnHIMgIqJKysfFFj4uuo3c6GNwM98Sz0sAVHOx1Qhs2tXyQGTsQ9haymBtIRMDIG3CA4vPSrfy9RZ6tZfMz+9Pg4yyGvFbJB7nqI8UfrPjGoD8qXYlTY+Le5CfPU+pFPA4Nw9OxWw+C+T39eIsOXATtx48wewXGqhlX1TZeOo2LGQS9G9UTcvV5Ss5C2j59X6MaVsTY5nZkZ5TXBNEREQVqrjvl99sF4hvB4Vizwfty3zvOlUKph4VTgte1I6JbUu9V9MSUomP78QPhuasaABUlFDC6jYBAgRBQM1PtyF02i4xM522kZOSUtrP2X4VayITEKVlM+HUzFx8sP4cJqw9i7tpWciW67++KOVxTpnWMgHAljgpHmXK8e3Oa2W6nsgcGDUImjNnDpo1awZHR0d4eXlhwIABuHaN/8MREVVGVhZSvBTmW+bRqZ71vbH2zYKU3RO71NJar20tDwR7O5V4r3/HtYGNZfH/RE7qVgffDgoFAPRuoPtaJTIPpc0ES8sqWGf0/l/nsPvyPTScvgvf7bqGpYdiSr1/4bVIq47H4VTcI9x+lCnuf5SZWxD0hM/Zq7GxbGl2XExC2Fe78enmi8XWUaUMf6IlICz71spE5sOoQdCBAwcwduxYHD9+HBEREZDL5ejWrRuePHlizGYREVE56BOaHyy83T6wXO7fO7SqWva74S38NOoEezti1oD8aXi2ljKt97k5uxcaVHcuNd33S2G+uDW3N34c3qTsjSaTVNIIijxPwKeb1dcejfkjChk5eVi4Nxpf/XdFLFcFE1vP38GpQiM+L/x0RPz5n3N38OLio2jz9T40n7UHh27c1xhBSs2UY9Z/l3ExMU2n9n+zMz/rXdFEEYXtvZqMXgsOoe+iwzrdk+h5Y9QgaMeOHRg1ahRCQkLQsGFDrFixAvHx8Th16lTpFxMRkVn5fkgjbBvfFm+1q1khz7OykOL6Vz3FY1tLGXZMbCcmbVj/djja1vLQ2DhWtf+RPjOJCu9lpNI7lCNE5qqkkaBlR2Kx7UKSTvfZcvYOlh6KwbjVZ/Di4qNieeHNY4v2s3kR17X2vV8PxaLPQvWAJU+hxMMnufjzRJzaJrQx90v/MnnL2Ts61yV6HplUYoS0tPxvONzc3LSez8nJQU5Ojnicnp7/l4hcLodcXnwKzIqger6x20Hmg32G9PU89JlanrbIyzNM6uoJnQLxw96b4rEiT6Hx3kgAhFZzwvnEdPRu4K12vo6XHZaNaILo5Mdi2fzBoWIdQSh+r5uiz9n0dkvUn75bPH6xiQ/ebheA/55u5llYI19nnE3Q7Rt9Mo7Cm7U+q8IjQ7r8v3smPhWt5u4t9vwfR2PQvpYHktJz8MGGC7j9KH//o6mbL+LTnnUwupX6CKhcLkfM/SeY/t8VjO1QE8398z9jKZVKtTrFtdGc/74RBAEKpVBqSnN6Nqb0b5M+bZAIZV01Z2BKpRL9+vVDamoqDh/WPjQ7bdo0TJ8+XaN89erVsLMrPh0rERE9fwQBeJQLTD+d/33eqNoKNHbX/CftiRy4nCpBqJsAay0z4B5kAzPO5N/j+5Z5UO0Ju/O2BNsSNC8YHqhAcy/N50w4ln+P12orEOomQCIpKCtsZtM8fH4qvzzAUUBsBldgVBY/hOfhYU5Bny0PHzbIw/8uFNz/h/A8zDkrQ1KWRDwGgBXXpTjzQKpWprL0qhQXHmk/Z06WX5fiepoEnzdWwM6kvvan8pKZmYlhw4YhLS0NTk4lr/00mS4xduxYXLx4sdgACACmTJmCSZMmicfp6enw9fVFt27dSn2h5U0ulyMiIgJdu3aFpWXxGYmIVNhnSF/sM9pNP70LANCkcWP0rO9dpnskOVyHg7UF+rQvmKrXJU+JVmfvoGWAG6o4WeP2oyzcSH5c7DNu2txE/MNMTH6xvpjy+JzkGpYdVU/n3L9Xd3x+Kn+h+8bxnZGckYMeCwrWiBz8sB1e/jUSd9Kyy/RaVDwcrJDyWHMvHTKeXr16ocXcfQDK7xvz2g2bARfOqD3zszN7AeSJxwDwz6MzwIP8jWpv2tbBex3z1+rJ5XIsvbpH7fqyypErsOHMHbQNckcNt4r/snrCsfy/GxQ+oegVVr3Cn19ZmNK/TapZYrowiSBo3Lhx2Lp1Kw4ePIjq1YvvpNbW1rC2ttYot7S0NPqbrmJKbSHzwD5D+mKf0c7CwqLM78unvUM0yiwtgVfCA8TjunY2qFut+LTZk7oHa5R93jcEY9oF4lxCKj5Yfw4LXm4MJ3sbLBsVBqUScHO0hZujLZr7uyHyVv5GsTU8HLXuG1NYrwbeJa5L+X5IQ3SqUwUNZ+wq8T5UsTafTcLDJ+U7ZcjSQv2jnQJSZGQXjOYcjH6IdVEJ2HP1vli2YO9NTOqm2X8BiP9PCYKAS3fScTr+EYa38BPXzimUgvhzUQv3xWDB3mhIJUDUZ12Rm6eEt7ONzq9FEAScjk9FkKcDnO3K/neehUzGvzMrgCn826TP840aBAmCgPfeew+bN2/G/v37ERAQUPpFREREWlRx0v3DVUWRSCTiprTdQ7whffphsVNwFbV6K8c0R8dv96NLvfzyCV1q4eMN5zGoaXVsOHVb477SUoKkFxrzW29T9PHG8+X+jMt31b8JD/58h9rx679Hab0uOSMbUzZewJCwalr3NxqxLBKHbqQAANZH3YaLnSU61vHCtzuvYdmoZlo3MD4ekx/YKwWgycwIAMD5ad1K3GC2sPVRt/HxxvPwcrRG5NQuxdbbdSkJ3s42CK3uovV8Kf+7UCVl1JViY8eOxapVq7B69Wo4OjoiKSkJSUlJyMrKMmaziIjIjCwbFYbPetctcXNTUyAt5ttyALC2kOHolM6Y0b8+AGBwmC8OfdwR37wYqrX+0OY1AABd6nppTDNaPaaF+POe99vgo9A83JjZDU422r/3fI8bvz5XyrrB6fR/LmPP1WS8ueqM1vOqAAgALiSm4dCNFMzYehlZcgXGrj4NALhxLwPzIq4jI/vpaJeWLr/5dCKA/L2M/jxRMFVUoRTw3poz4j5Lmbl5YtCYnJGjeaOnriVl4M2Vp9Bv0RG1chNZ8k4mzKhB0OLFi5GWloYOHTqgatWq4p+//vrLmM0iIiIz0im4Csa0rZi02xXJ180OUqkEH/eoo3nO1Q6XpnfHryPC8O+4Npg5ID94GtS0OloFeYj1arjZobp9/s+7J7XX+pz3OhVsKvtqS829lahyuJdesAZNXnxiRK3yFEokp2ej6/cHsWDPDczZfhWCICAy9qFG3S//uQQAeHvVKUzdfBEx9/OzM+65cg//nrsjZtO7lZKpdp2ymLzlqusLy5Yr0Pm7A+KxRIftXzOy5Th6MwWK0nbKpeeG0afDERERUfHe7RCEu6nZuJCYhrMJqQAAAQLsrfP/CXe2s8SrLf0wOKw6rC20bwALAF5ONrgxqycspBJIJBKcinsEC6kEVhYF34faaUufR5VCVKHNXK+kFvSJhtN34dyX3Uq89kmuAtO3XhaPz8an4ucDMTo99+GTXNT0BJ7klpyF7st/LiHhUSbaBHmofelR+JPknG1X0LehDxJTsxCTUvL+RyuPx2Hf1WT8NLwJbCxlGPrrcVxMTMcXferhtTZcnlEZMHE6ERGRiZs5oD42v9sKLWu6oUE1Z/i6ambaKikAUrGUScWkC039XNHQ10Wn57et5YGBjauhblXjZmKlipeWJceKI7El1lEoBbU9sSQS4OsdV4utv+p4wTQ4AZpfiguCUDCl7qmVx+Ow/9p9fPXfFZyKKxhhUha6dsnBGPRZeFhzs1lJ/lS9D9efQ/yD/BGmz7dcxN6ryVh9Ih4AcDExfy3VjELBHD3fTCI7HBEREZVMIpFgzRstIQglry96Fs393bCk0Df4v7/WHBcT0zCqlT/srS0gCAICpmwr9T4LhjbG4Rv3sS5KM6kDmZ9p/+oXGFy/l1Hi+c+2XBR/funnYwCAsEJr+krrYy8uPoat77WBn7sdtM1ey5Yr1I5z85To+v1BAMC5hFREFJoa+t+Fu3g1nNNAKyMGQURERGZCIpGUS6arQx93xJW76egU7KVW3q6WB9rX9lR7/oa3w7Hr8j38clD7dKcudb3Qr6EP+jX00QiCqrnYIjGVyY+ed3KF/ssdCk/H00X/H49AoRQwJMxX49zEv86qHc/ffV38+Uay+hqiU3GPsGhvdInPirh8DyuPx+F/g0LhZYJZKKlsOB2OiIiokvN1s0O3EG+N/Ym07VcU5u+GT3vVVSu7Masnlo0Kw86J7bD4labFPmfb+LZqxyE++k2vC/Z2xN4PtCd4oMpFlcDgr6iEUusW3TS46PS7H/bcUDu+dCcN66MSMHJZJKJuPcQbf0Th4PX7mPbvJbFOzP3H6LvwMHZc1L5f16MnuZi88Tyibmkmhzgd/wjLDsfqtDZeqRSw8ngcLt/RfRNQ0g1HgoiIiEg064X6mLr5IhYNa1xivTpVHHHtXgasLKSwlEk19j7SpvCGl0FeDtj4TiusjYyHi50V6lZ1wvqoBByPfSCuzyiqaBBV1LS+9RD/MAtOthaYv/tGiXU3vB2OxftvYs/V5FLbTc+X3w6XvMap94LD4s8HrhdsKrvtQhKSM7Lh5WiDSevO4UJiGt5edQrr3w5HM383tXt89d8VbDx9G2tPJuDW3N5IzczFjH8vY1BYdQz79QQAwMvJGn1CfUpsy7aLd/H50+mDt+b21ut1Usk4EkRERESi4S38cHVmj1I/nC0dGYaBTarhn3Gti63j+HRvogAPe3HPo+9eaoiWNd2w7q1w2FjKMKp1AAY0roY63o74rE89/DaymXj91F511aboSaUSjfVQOye2E39uHuCOL/rWQ+8GVdXqaEvoEObvht9GNdMop+efKg13Wby85DgAIL1Q4oaXfj6mMaoTm6I+7W7OtqvYdCZRDIAAILrI1LyrSen4PuI6MnPz8OXfF7H0UAyu39NMAa6v/deS0em7/Tilx5TDuAdPcOlO2jM/25RxJIiIiIjU2FiWnmnO180O8wY3KrHOyaldIFco4WhTMAL0YtPqeLFp9WKvqeJkg6UjwmBvbYHwQHeMbOWP7yKuoX0tT63163g7YvekdriTmo16T6fX1ariKJ5f+2ZLNPd3w6Cfj+J0fGqJ7e1QxxP7r90vsQ5VbjEpTyBXKBFzXz0F97V7GQj2zu9/t1KeIDNXPTlDwiP1fY8AYP7uG+jb0Ac1Pexx5W4Gei04BEB9et6EzrU0rlPZcfEubCxl6FDHq9g6ADBq+UkAwCtLT+DKzB4l1lVp/+1+AEDk1M7wcnw+10ExCCIiIqJyYWMp0ymgKqpLvYKpdVYWUkzpqb4GaWjzGlgTGQ/Hp3slBXk5IsjLUa3Orbm9oVAKkD0dOdr0bmsM/vkYIrWs0VApLedEt3pVsOvyvRLrtAhwwwktm4TS82P8mjMaZT3mH8LuSe3RZd4BLVcA0mIymoxcFonxnWvh4w3ntZ4vbtXQ/YwcvL3qNAAgdk4vrev3isoqkjVPm9TMXGw+kygexz/IfG6DIE6HIyIiIrPyWe+6mNqrLrZNKHmNkKzI1LnZAxugpqc95g1uKJapNgKVSIAv+oaUeL/OddW/ca9dxUGjzh+vNxd/nje4Ia7M0O2bdzIf24tJhlBcAHTy1kM8fJKr9dztR1nFBkAAoFAqtZY/yiy437yI68hT5NfLyJbj4PX74rHm/UpOxjDxr7OYrmdKdHPFkSAiIiIyK/bWFnijXU29rwvycsDeDzqolTnbWuLS9O6QSAA7Kwuc+bwr7KxlqPPZDrHO/15qiGBvR9Sr6oQLiWlYdTx/g01bLaNcskLfyAsCyiWlOZkX1V5IZfHjvpviz0lp2XCwsYCDtQWWFUrusHBvNBbujYaNpRTZ8vzg54OutfGelql0LWbvwcZ3wnE1KQPN/d3w4uKj6Bbijck9gwFAYzqotpBJrlDCUibFwye5uJiYhhZ+zmV+fcbEIIiIiIgqNXvrgo9DrvZWGucHFVrD1KtBVTEIerFpdZy7XbB4fP6QRrCQScUPo80D3GBjKcOkrrUxL+K6xn2J9NFyzh7YWcnw64gwrD2pmRpcFQABwJKDMRjczFetbwNAyuMccb2Pys8HbqJdLQ/ceqC5bqmohXtuYN7u65jzQgNM3nQBADD3hRDYluH1GBunwxEREREVUd01/2NdkJf6lLeWAe7oEeKN9zoF4ZUWfmL590MaYkDjagCAqM+64sjkTvB1swMAjC9hcXtJGvq6qB2f+bxrqdeMCC9oU2lpzsn8ZOYqcONeRqn1HufkocXsPaj/5U6d7jts6Ql8uvmCRrlCKeBIdAoynmbD+y7iOgQBYgAEALuvmGeaeY4EERERERWxekxLLDsSi9fbBKiVS6US/PxqwYawkVM749KddLXsdQ7W+VOWntVX/euj76KCPWtc7a2wfFQzjF5xUiybP6QRJv51Vjz+pEcwqjjZoEd9bwR6OmDcas1F/GTeKjLoePmX/JTgDao544/Xmmuto0tSBlPEkSAiIiKiImq422FavxBxNKc4Xo426FjHS2P/oqK2jG2N8Z2C1Mr6NSx+L6ZfXm2KBtWdceCjDgCALk+TMnQM9sLqN1rg0McdcWtub3H0ScXe2gJjOwYh0DN/BOvFJvlT+Rr5uuCj7nVKbCOZh8PRKRX+zAuJaZj27yWt58w0BmIQRERERFTeGvm6YFI39SCk8KLzolPmGtVwAQD4udvj1tzeWFpoE9lWgR6lBmcqs16oj99GhmHNGy1hb1V8uvLm/m463Y8qr7/P3tFaXlz6b1PHIIiIiIioglnKJGhYvSCr1qSutXF0cifxuCx7s6hGfQqzsZShc90qsLWSIayEQGfd2+FqxzvGt1Y79nK0LvX5m95tpWNLgY51tG9+S+Znx6WS984yVVwTRERERFRBVr3eAl/+cxHfDApFaHUXWEglaB3kAQDwcbHFgqGN4WSj38ezla83x18nEzC1d90S69Wv5oyN77RCNRdbPMrMRcTle8VmrQv0tEfbWh44dCN/6tWiYU0weElBqufwmu44FvMAQH4A16O+N2pXcdR6r6J8nG1gKeP38GRcDIKIiIiIKkibWh7YU2ivolGt1RMvlLROqDhta3mibS3dRlaa+rkCALydbeBub4V5Edc1MuCFuuWnWl75egv4T/4PAKAUCibvjW7tDz83OzEIKi773Vvta2LJgRiNcolEYrbrSOj5wSCIiIiIqBLycrLBuS+7we7pWiFbSxmy5ArUddHcIlMQgH/HtcF/F+5iXKcgWMokOH87DR2CvdTqFR4hmtKzrtYgqHmAGzJz80psWyNfF5xNSC3jKwMuTOuGDaduY/q/l8t8D9JdtsLYLdAfxyKJiIiIKilnW0txatq+Dztg4csN0dKrIAhqUM0ZjtYWaOTrggbVnTG5ZzAcrC1gbSHDvCGNNEauHItM5VMlXGgT5AEnGwu81ykI0/qFaLQjtLozZvYPQXhNdwDAyFZ+qFvVSefXEeBhj/6NfPB5n3qIndMLjjaWGF1klI3Kz4YY8wspOBJERERERPB2tkGPkCrYFldQ9vfY1shTCrCy0O1DroudpdrxmjdbIiNbDhc7K7XyLnWrYGehBfX/jGsDABjSrAZuPXiCWl4O6BRcBX0WHkLCwyy1ayM/7Yzvd9+AVAL8eSIeAPDHa811zpjn4WCN5gGu2HYhSaf6VLpHueY3v5FBEBERERFpJZVKYFXKHkiFfdwjGPEPMzG0eQ0AgEwq0QiAgPxMdrZWMvx77o7aiI2VhVRMsOBsa4n+Dath0b5otWsVgoA5AxsAAMZ2DMKjzFydAyAAqFvVEVN61sXFxHQMaeaLb3deE8/9/EoTNPFzxfmENMSmPMGsbVd0vm9lFp3OIIiIiIiIKikPB2usfTO81HpSqQR9Qn3QJ7TkRBChhdKIq+QpCqbr+bjYwsfFttjrV4xuhq3n76JzsBfe+fM0gPwAzNfNDgc/7ojM3Dy1IKhH/aoAgC718lOUMwh6fjEIIiIiIiKT1LVeFSwY2hi1vBzQ84dDAACFUjNxQ3E61PFChzpeEAQBn/WuC5lUgv6NCgIvmR6jXPR8Mb9VTERERERUKUgkEvRr6IM6hfYgcrXXnF6ny33GtK2J0a0DICmUn9vaQib+3LeE9OTu9lYIre6Mf8e1QTP//DTjr7b0w7q3Sh/1AoAzn3fFtvFtsendVrCSScUEEGQ8HAkiIiIiIpMmlUqwc2I75OQp4GxrWfoFejg5tQt2XkpSGyEq6ou+9dC/UTUAwG+jmuFEzEO0q+0BawsZeodWxX/n7+LzPvXwz7k7OKcltbervZUYvJ2f1g1WMilqfrpNPN+lrhd2X0k26OuqaIKg+widKWAQREREREQmr463Y+mVysDT0RqvtPTTeu6VljUQdesRuod4i2VONpboWq+KePzjsCb4cVj+z70aeGPJgRiMbOWPr7Zexp6rmoGNjaVM7fjnV5rCycZCaxBU1dkGd9Oyy/KyKpzEzHbA5XQ4IiIiIiItvhrQADsmttMIXIpT1dkW0/qFIMDDvtSg4PAnHbHmjZboUd8bxY2hHJvSGSPCCwK0HRPbij/X9LTXqU2kHUeCiIiIiIgMTFbKUEN1VztUd81P7e3tbKNxftv4/ICn8CyzYG8nbHwnHNlyJVrWdMfZhEd4cfExAEAtLwfcSH6sU9uGNq+BNZHxOtV9XjEIIiIiIiIysJJSdxcV6OmAH15uBHd7azjZWqCOt6OYtCE80B0rjxfsYNvUz63QlQWjTf+Ma4O6X+wo9hlb32uDn/ZHo0vdKhjYpDpGhPuhipMNmsyMEOu80LgaXmnph20X7uK3w7E6t98cMQgiIiIiIjKw97vWxoPHuRjQuOS9kFRUiReK6lnfG0tHhKGuj5PGucIz7myttE/Z+3dcG1RxtoaXow1+Gt5ULK9bVfN+s16oDzsrCzT1c8WlO2k4HvNQp7abI64JIiIiIiIyMCcbSywY2hidgquUXrkEEokEXepVQTUtI0sB7qWvC2pQ3RlejprT7UqzfFRzLB0RJh53D3m212FqOBJERERERGSGXO2tsO/DDrB9mrihfyMf/H32DloEuKFzXS+0reVZ6j3+G98GvRccBqC+eaytlQxd6lXBng/aw0omhZu9FUK+3Fk+L8QIjBoEHTx4EN9++y1OnTqFu3fvYvPmzRgwYIAxm0REREREZDYCPApGg2a/0ACdgr3QMdgLTja67acU4uOMJa82hYVUorZ5rEqgp4P4s0RSkKjhzzEtMHzpiWdrvBEZdTrckydP0LBhQ/z444/GbAYRERERkdmzt7ZA/0bVdA6AVLqHeKNz3dKnu33cPRhAfna51kEeODalEwCgZ3WF/o01MqOOBPXs2RM9e/Y0ZhOIiIiIiEgHb7evia71vFDTI390qKqzLW7M7IZt27YZuWX6M6s1QTk5OcjJyRGP09PTAQByuRxyudxYzRLbUPi/RKVhnyF9sc+QvthnSF/sM1QaP1cbKBR5UDwd/DGlPqNPGySCIBS3SW2Fkkgkpa4JmjZtGqZPn65Rvnr1atjZ2ZVj64iIiIiIyJRlZmZi2LBhSEtLg5OTZgrwwswqCNI2EuTr64uUlJRSX2h5k8vliIiIQNeuXWFpqd88TKqc2GdIX+wzpC/2GdIX+wzpy5T6THp6Ojw8PHQKgsxqOpy1tTWsra01yi0tLY3+pquYUlvIPLDPkL7YZ0hf7DOkL/YZ0pcp9Bl9ns/NUomIiIiIqFIx6kjQ48ePER0dLR7Hxsbi7NmzcHNzQ40aNYzYMiIiIiIiel4ZNQiKiopCx44dxeNJkyYBAEaOHIkVK1YYqVVERERERPQ8M2oQ1KFDB5hIXgYiIiIiIqokuCaIiIiIiIgqFQZBRERERERUqTAIIiIiIiKiSoVBEBERERERVSoMgoiIiIiIqFJhEERERERERJUKgyAiIiIiIqpUjLpP0LNS7TGUnp5u5JYAcrkcmZmZSE9Ph6WlpbGbQ2aAfYb0xT5D+mKfIX2xz5C+TKnPqGICXfYhNesgKCMjAwDg6+tr5JYQEREREZEpyMjIgLOzc4l1JIIuoZKJUiqVuHPnDhwdHSGRSIzalvT0dPj6+iIhIQFOTk5GbQuZB/YZ0hf7DOmLfYb0xT5D+jKlPiMIAjIyMuDj4wOptORVP2Y9EiSVSlG9enVjN0ONk5OT0TsAmRf2GdIX+wzpi32G9MU+Q/oylT5T2giQChMjEBERERFRpcIgiIiIiIiIKhUGQQZibW2NL7/8EtbW1sZuCpkJ9hnSF/sM6Yt9hvTFPkP6Mtc+Y9aJEYiIiIiIiPTFkSAiIiIiIqpUGAQREREREVGlwiCIiIiIiIgqFQZBRERERERUqTAIMpAff/wR/v7+sLGxQYsWLRAZGWnsJlEFmDNnDpo1awZHR0d4eXlhwIABuHbtmlqd7OxsjB07Fu7u7nBwcMCLL76Ie/fuqdWJj49H7969YWdnBy8vL3z00UfIy8tTq7N//340adIE1tbWCAoKwooVK8r75VE5mzt3LiQSCSZOnCiWsb+QNomJiXjllVfg7u4OW1tbNGjQAFFRUeJ5QRDwxRdfoGrVqrC1tUWXLl1w48YNtXs8fPgQw4cPh5OTE1xcXPD666/j8ePHanXOnz+Ptm3bwsbGBr6+vvjmm28q5PWRYSkUCnz++ecICAiAra0tAgMDMXPmTBTOhcU+U7kdPHgQffv2hY+PDyQSCbZs2aJ2viL7x/r16xEcHAwbGxs0aNAA27ZtM/jr1UqgZ7Z27VrByspKWLZsmXDp0iXhjTfeEFxcXIR79+4Zu2lUzrp37y4sX75cuHjxonD27FmhV69eQo0aNYTHjx+Ldd5++23B19dX2LNnjxAVFSW0bNlSaNWqlXg+Ly9PqF+/vtClSxfhzJkzwrZt2wQPDw9hypQpYp2YmBjBzs5OmDRpknD58mVh4cKFgkwmE3bs2FGhr5cMJzIyUvD39xdCQ0OFCRMmiOXsL1TUw4cPBT8/P2HUqFHCiRMnhJiYGGHnzp1CdHS0WGfu3LmCs7OzsGXLFuHcuXNCv379hICAACErK0us06NHD6Fhw4bC8ePHhUOHDglBQUHC0KFDxfNpaWlClSpVhOHDhwsXL14U1qxZI9ja2gpLliyp0NdLz27WrFmCu7u7sHXrViE2NlZYv3694ODgIPzwww9iHfaZym3btm3C1KlThU2bNgkAhM2bN6udr6j+ceTIEUEmkwnffPONcPnyZeGzzz4TLC0thQsXLpT7e8AgyACaN28ujB07VjxWKBSCj4+PMGfOHCO2iowhOTlZACAcOHBAEARBSE1NFSwtLYX169eLda5cuSIAEI4dOyYIQv5fRFKpVEhKShLrLF68WHBychJycnIEQRCEjz/+WAgJCVF71pAhQ4Tu3buX90uicpCRkSHUqlVLiIiIENq3by8GQewvpM0nn3witGnTptjzSqVS8Pb2Fr799luxLDU1VbC2thbWrFkjCIIgXL58WQAgnDx5Uqyzfft2QSKRCImJiYIgCMJPP/0kuLq6iv1I9ew6deoY+iVROevdu7fw2muvqZUNHDhQGD58uCAI7DOkrmgQVJH9Y/DgwULv3r3V2tOiRQvhrbfeMuhr1IbT4Z5Rbm4uTp06hS5duohlUqkUXbp0wbFjx4zYMjKGtLQ0AICbmxsA4NSpU5DL5Wr9Izg4GDVq1BD7x7Fjx9CgQQNUqVJFrNO9e3ekp6fj0qVLYp3C91DVYR8zT2PHjkXv3r01fqfsL6TNP//8g7CwMLz00kvw8vJC48aN8euvv4rnY2NjkZSUpPY7d3Z2RosWLdT6jYuLC8LCwsQ6Xbp0gVQqxYkTJ8Q67dq1g5WVlVine/fuuHbtGh49elTeL5MMqFWrVtizZw+uX78OADh37hwOHz6Mnj17AmCfoZJVZP8w5r9XDIKeUUpKChQKhdoHEgCoUqUKkpKSjNQqMgalUomJEyeidevWqF+/PgAgKSkJVlZWcHFxUatbuH8kJSVp7T+qcyXVSU9PR1ZWVnm8HCona9euxenTpzFnzhyNc+wvpE1MTAwWL16MWrVqYefOnXjnnXcwfvx4/P777wAKfu8l/TuUlJQELy8vtfMWFhZwc3PTq2+ReZg8eTJefvllBAcHw9LSEo0bN8bEiRMxfPhwAOwzVLKK7B/F1amI/mNR7k8gqiTGjh2Lixcv4vDhw8ZuCpmohIQETJgwAREREbCxsTF2c8hMKJVKhIWFYfbs2QCAxo0b4+LFi/j5558xcuRII7eOTNG6devw559/YvXq1QgJCcHZs2cxceJE+Pj4sM8QPcWRoGfk4eEBmUymkb3p3r178Pb2NlKrqKKNGzcOW7duxb59+1C9enWx3NvbG7m5uUhNTVWrX7h/eHt7a+0/qnMl1XFycoKtra2hXw6Vk1OnTiE5ORlNmjSBhYUFLCwscODAASxYsAAWFhaoUqUK+wtpqFq1KurVq6dWVrduXcTHxwMo+L2X9O+Qt7c3kpOT1c7n5eXh4cOHevUtMg8fffSROBrUoEEDvPrqq3j//ffFEWj2GSpJRfaP4upURP9hEPSMrKys0LRpU+zZs0csUyqV2LNnD8LDw43YMqoIgiBg3Lhx2Lx5M/bu3YuAgAC1802bNoWlpaVa/7h27Rri4+PF/hEeHo4LFy6o/WUSEREBJycn8YNPeHi42j1UddjHzEvnzp1x4cIFnD17VvwTFhaG4cOHiz+zv1BRrVu31ki9f/36dfj5+QEAAgIC4O39//buP7Sq+o/j+Otu6yzn3O5wY9a46zJ06vSm64c1DZM2jIkxFfwxZOmCZFnQIPOfCg3SluTQlhEFNTVBI01RUZn7JQ6c25qWeilR14Qu1rTl1oKW990f0sWr1nff73c/0vt8wPlj577P/XzO2QfufXHufd9RYf/zq1evqrGxMWzddHZ2qqWlJVRTU1OjYDCoxx57LFRz5MgR9fb2hmqqqqo0duxYJSUlDdj5of/19PQoKir8LV50dLSCwaAk1gz+2WCujyF9vRrw1gsRYPv27RYbG2uVlZV25swZW7Zsmbnd7rDuTbg7vfDCC5aYmGh1dXUWCARCW09PT6impKTE0tPTraamxpqbmy0nJ8dycnJCj//V8njmzJl24sQJO3jwoKWkpNy25fGrr75qfr/fNm3aRMvju8SN3eHMWC+41fHjxy0mJsbWrFljZ8+etW3btllcXJx99tlnoZqysjJzu922Z88e+/rrr62goOC27Wyzs7OtsbHRjh49amPGjAlrZ9vZ2WmpqalWVFRkp06dsu3bt1tcXBztju9AS5YssbS0tFCL7F27dllycrKtXLkyVMOaiWxdXV3W2tpqra2tJsnKy8uttbXVvv/+ezMbvPXR0NBgMTEx9u6775rf77dVq1bRIvtOU1FRYenp6eY4jk2ZMsWOHTs21FPCIJB02+3TTz8N1fz222+2fPlyS0pKsri4OJs7d64FAoGw52lra7P8/HwbNmyYJScn2yuvvGK9vb1hNbW1tTZ58mRzHMcyMjLCxsCd6+YQxHrB7ezdu9cmTpxosbGxNm7cOPvoo4/CHg8Gg/bGG29YamqqxcbGWm5urn377bdhNZcvX7bCwkKLj4+3hIQEKy4utq6urrCakydP2hNPPGGxsbGWlpZmZWVlA35u6H9Xr161l19+2dLT0+3ee++1jIwMe+2118JaFbNmIlttbe1t378sWbLEzAZ3fXz++eeWmZlpjuPYhAkTbP/+/QN23jdymd3w88EAAAAAcJfjO0EAAAAAIgohCAAAAEBEIQQBAAAAiCiEIAAAAAARhRAEAAAAIKIQggAAAABEFEIQAAAAgIhCCAIAAAAQUQhBAIC7ltfr1YYNG4Z6GgCAfxlCEACgXyxdulRz5syRJM2YMUOlpaWDNnZlZaXcbvct+5uamrRs2bJBmwcA4M4QM9QTAADg7/z+++9yHOd/Pj4lJaUfZwMAuFtwJwgA0K+WLl2q+vp6bdy4US6XSy6XS21tbZKkU6dOKT8/X/Hx8UpNTVVRUZE6OjpCx86YMUMvvfSSSktLlZycrKefflqSVF5eLp/Pp+HDh8vj8Wj58uXq7u6WJNXV1am4uFi//PJLaLzVq1dLuvXjcO3t7SooKFB8fLwSEhK0YMECXbp0KfT46tWrNXnyZG3dulVer1eJiYlatGiRurq6QjVffPGFfD6fhg0bppEjRyovL0+//vrrAF1NAMBAIAQBAPrVxo0blZOTo+eff16BQECBQEAej0ednZ166qmnlJ2drebmZh08eFCXLl3SggULwo7fvHmzHMdRQ0ODPvzwQ0lSVFSU3nvvPZ0+fVqbN29WTU2NVq5cKUmaOnWqNmzYoISEhNB4K1asuGVewWBQBQUFunLliurr61VVVaXz589r4cKFYXXnzp3T7t27tW/fPu3bt0/19fUqKyuTJAUCARUWFuq5556T3+9XXV2d5s2bJzMbiEsJABggfBwOANCvEhMT5TiO4uLiNGrUqND+999/X9nZ2Vq7dm1o3yeffCKPx6PvvvtOmZmZkqQxY8Zo3bp1Yc954/eLvF6v3nrrLZWUlOiDDz6Q4zhKTEyUy+UKG+9m1dXV+uabb3ThwgV5PB5J0pYtWzRhwgQ1NTXp0UcflXQ9LFVWVmrEiBGSpKKiIlVXV2vNmjUKBAL6448/NG/ePD3wwAOSJJ/P939cLQDAUOBOEABgUJw8eVK1tbWKj48PbePGjZN0/e7LXx5++OFbjj18+LByc3OVlpamESNGqKioSJcvX1ZPT0+fx/f7/fJ4PKEAJElZWVlyu93y+/2hfV6vNxSAJOm+++7Tjz/+KEmaNGmScnNz5fP5NH/+fH388cf6+eef+34RAAD/CoQgAMCg6O7u1jPPPKMTJ06EbWfPntX06dNDdcOHDw87rq2tTbNnz9aDDz6onTt3qqWlRZs2bZJ0vXFCf7vnnnvC/na5XAoGg5Kk6OhoVVVV6cCBA8rKylJFRYXGjh2rCxcu9Ps8AAADhxAEAOh3juPo2rVrYfseeughnT59Wl6vV6NHjw7bbg4+N2ppaVEwGNT69ev1+OOPKzMzUz/88MN/HO9m48eP18WLF3Xx4sXQvjNnzqizs1NZWVl9PjeXy6Vp06bpzTffVGtrqxzH0Zdfftnn4wEAQ48QBADod16vV42NjWpra1NHR4eCwaBefPFFXblyRYWFhWpqatK5c+d06NAhFRcX/2OAGT16tHp7e1VRUaHz589r69atoYYJN47X3d2t6upqdXR03PZjcnl5efL5fFq8eLG++uorHT9+XM8++6yefPJJPfLII306r8bGRq1du1bNzc1qb2/Xrl279NNPP2n8+PH/3QUCAAwpQhAAoN+tWLFC0dHRysrKUkpKitrb23X//feroaFB165d08yZM+Xz+VRaWiq3262oqL9/OZo0aZLKy8v1zjvvaOLEidq2bZvefvvtsJqpU6eqpKRECxcuVEpKyi2NFaTrd3D27NmjpKQkTZ8+XXl5ecrIyNCOHTv6fF4JCQk6cuSIZs2apczMTL3++utav3698vPz+35xAABDzmX09QQAAAAQQbgTBAAAACCiEIIAAAAARBRCEAAAAICIQggCAAAAEFEIQQAAAAAiCiEIAAAAQEQhBAEAAACIKIQgAAAAABGFEAQAAAAgohCCAAAAAEQUQhAAAACAiPInObdc8vPZndkAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved checkpoint to chatbot_10000.pth\n",
            "Training complete! Final model saved to chatbot_final.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# chatting functions"
      ],
      "metadata": {
        "id": "92HBaQ-2j_OJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GreedySearchDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(GreedySearchDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, input_seq, input_length, max_length):\n",
        "        # Ensure lengths stay on CPU\n",
        "        if input_length.is_cuda:\n",
        "            input_length = input_length.cpu()\n",
        "\n",
        "        # Forward pass through encoder\n",
        "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
        "\n",
        "        # Prepare decoder initial state\n",
        "        decoder_hidden = encoder_hidden[:self.decoder.n_layers]\n",
        "\n",
        "        # Initialize decoder input with SOS token\n",
        "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
        "\n",
        "        # Track decoded tokens\n",
        "        decoded_tokens = []\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            decoder_output, decoder_hidden = self.decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "\n",
        "            # Get most likely token\n",
        "            _, topi = decoder_output.topk(1)\n",
        "            ni = topi.squeeze().item()\n",
        "\n",
        "            # Stop at EOS token\n",
        "            if ni == EOS_token:\n",
        "                break\n",
        "\n",
        "            decoded_tokens.append(ni)\n",
        "            decoder_input = torch.LongTensor([[ni]]).to(device)\n",
        "\n",
        "        return decoded_tokens"
      ],
      "metadata": {
        "id": "B1OTi6yEjvGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(encoder, decoder, voc):\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    searcher = GreedySearchDecoder(encoder, decoder)\n",
        "\n",
        "    print(\"Chat with the bot (type 'quit' or 'exit' or 'q' to exit)\")\n",
        "    while True:\n",
        "        try:\n",
        "            input_sentence = input(\"You: \")\n",
        "            if input_sentence.lower() in ['quit', 'exit', 'q']:\n",
        "                break\n",
        "\n",
        "            # Normalize and tokenize\n",
        "            input_sentence = normalizeString(input_sentence)\n",
        "            tokens = [word for word in input_sentence.split(' ') if word]\n",
        "\n",
        "            # Convert to indexes with UNK handling\n",
        "            indexes = []\n",
        "            for word in tokens:\n",
        "                if word in voc.word2index:\n",
        "                    indexes.append(voc.word2index[word])\n",
        "                else:\n",
        "                    indexes.append(UNK_token)  # Use unknown token\n",
        "            indexes.append(EOS_token)\n",
        "\n",
        "            # Create tensors - LENGTHS MUST STAY ON CPU\n",
        "            lengths = torch.tensor([len(indexes)])\n",
        "            input_batch = torch.LongTensor([indexes]).transpose(0, 1).to(device)\n",
        "\n",
        "            # Decode response\n",
        "            tokens = searcher(input_batch, lengths, MAX_LENGTH)\n",
        "            decoded_words = [voc.index2word[token] for token in tokens]\n",
        "\n",
        "            # Format response (remove special tokens)\n",
        "            response = ' '.join([word for word in decoded_words\n",
        "                                if word not in ['EOS', 'PAD', 'SOS', '<eos>', '<pad>', '<sos>']])\n",
        "            print(f\"Bot: {response}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {str(e)}\")"
      ],
      "metadata": {
        "id": "numzelR9j7Jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# start chatting"
      ],
      "metadata": {
        "id": "8g8YM74G800J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run all Define Models cells\n",
        "# Run maskNLLLoss function"
      ],
      "metadata": {
        "id": "tkuWSxp09Ckr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load checkpoint of final model\n",
        "checkpoint = torch.load('/content/chatbot_final.pth', map_location=device, weights_only=False)\n",
        "\n",
        "# Extract components\n",
        "voc = checkpoint['voc']\n",
        "encoder_weights = checkpoint['encoder']\n",
        "decoder_weights = checkpoint['decoder']\n",
        "\n",
        "# Recreate models\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "\n",
        "# Load weights\n",
        "encoder.load_state_dict(encoder_weights)\n",
        "decoder.load_state_dict(decoder_weights)\n",
        "\n",
        "# Move to device and set eval mode\n",
        "encoder = encoder.to(device).eval()\n",
        "decoder = decoder.to(device).eval()"
      ],
      "metadata": {
        "id": "lJXtUv0187mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start chatting 🎉\n",
        "chat(encoder, decoder, voc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "KwN1GKjb5K-4",
        "outputId": "f64bfd51-159c-4f83-b209-a492925551f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chat with the bot (type 'quit' or 'exit' or 'q' to exit)\n",
            "You: hello\n",
            "Bot: hello .\n",
            "You: how are you ?\n",
            "Bot: okay .\n",
            "You: where am i ?\n",
            "Bot: you re in a hospital in london .\n",
            "You: do you drink water ?\n",
            "Bot: no .\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-729863664>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# start chatting 🎉\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-109-2330664421>\u001b[0m in \u001b[0;36mchat\u001b[0;34m(encoder, decoder, voc)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0minput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'quit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}